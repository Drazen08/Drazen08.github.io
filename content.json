{"meta":{"title":"Drazen","subtitle":"the stack of it nerds","description":"start from zero","author":"JFuncnovic","url":"http://sunjx93.com"},"pages":[],"posts":[{"title":"netty 总结一下","slug":"netty","date":"2019-03-22T08:00:09.000Z","updated":"2019-03-25T01:54:43.271Z","comments":true,"path":"2019/03/22/netty/","link":"","permalink":"http://sunjx93.com/2019/03/22/netty/","excerpt":"自己有个毛病，写笔记的时候不知道从哪里开始说起…以工作中用到的tcp为例子，总结一下netty的用法和坑。","text":"自己有个毛病，写笔记的时候不知道从哪里开始说起…以工作中用到的tcp为例子，总结一下netty的用法和坑。 Giao 哥镇楼 我是假的目录 0.0 : 服务端启动 怎么写逻辑处理类handler 持有合法channel以及发送消息 超时策略的处理方式及注意事项 拆包/粘包处理思路 客户端异常情况的重连方式 如何使用netty开发websocket端 如何用客户端代码搞jmeter测试高访问量下服务端抗压能力 netty 多服务端的开发思路 剩下的一些坑（crc8 ） 1.服务端启动 ServerBootstrap这个类代表一个socket服务，创建它，然后把它放在服务端的容器中。 12345678910111213ServerBootstrap b = new ServerBootstrap();// 这里的EventLoopGroup 可以设置数量b.group(new EventLoopGroup(),new EventLoopGroup()) .channel(NioServerSocketChannel.class) // 放置自己的channelHandler,如果想使用spring 上下文也可以autowired .childHandler(new MyChannelHandler()); // 这里是netty的配置属性Map&lt;ChannelOption&lt;?&gt;, Object&gt; tcpChannelOptions = (...);Set&lt;ChannelOption&lt;?&gt;&gt; keySet = tcpChannelOptions.keySet();for (@SuppressWarnings(&quot;rawtypes&quot;) ChannelOption option : keySet) &#123; b.option(option, tcpChannelOptions.get(option));&#125; 服务端的配置属性我用的不多，大概是三个 属性放置在ChannelOption作为key的Map中，在声名ServerBootstrap时放入ServerBootstrap.option(?) 方法中 我的channelOption: name value 解释 ChannelOption.SO_KEEPALIVE true Socket参数，连接保活，默认值为False。启用该功能时，TCP会主动探测空闲连接的有效性。可以将此功能视为TCP的心跳机制，需要注意的是：默认的心跳间隔是7200s即2小时。Netty默认关闭该功能。 ChannelOption.SO_BACKLOG 1 Socket参数，服务端接受连接的队列长度，如果队列已满，客户端连接将被拒绝。默认值，Windows为200，其他为128。 ChannelOption.TCP_NODELAY true TCP参数，立即发送数据，默认值为Ture（Netty默认为True而操作系统默认为False）。该值设置Nagle算法的启用，改算法将小的碎片数据连接成更大的报文来最小化所发送的报文的数量，如果需要发送一些较小的报文，则需要禁用该算法。Netty默认禁用该算法，从而最小化报文传输延时。 具体的配置可以看Api文档，或者看这篇文章： netty Channel Option 2.怎么写逻辑处理类handler 先介绍一下我们项目中的通信规则：数据消息是一串byte数组，校验方式用的CRC8，分割符是十六进制的FFFF,占据两个byte格式是这样的： 头部 内容 crc8 结尾 长度(byte)： 1 x 1 2 简单的ChannelHandler 代码：1234567891011121314151617181920212223242526@ChannelHandler.Sharable // 这个注解的意思是handler可以被多个channel安全的共享public class MyChannelHandler extends ChannelInboundHandlerAdapter&#123; // 主要的消息接收的方法，所有的消息都走的这个方法 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123;&#125; // 字面意思，代表消息接收完毕时调用的方法 @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123;&#125; // 发生异常时调用该方法 @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123;&#125; // socket最初连接的方法 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123;&#125; // socket断开时调用该方法 @Override public void channelInactive(ChannelHandlerContext ctx) &#123;&#125; // socket 通信超时时调用该方法 @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123;&#125;&#125; GIAO！一个简单的channelHandler 大概就是上面这个样子，这里有几个需要注意的地方： ChannelHandler可以继承ChannelInboundHandlerAdapter，或者是它的子类SimpleChannelInboundHandler&lt;T&gt; SimpleChannelInboundHandler对父类进行了简单的封装，当使用SimpleChannelInboundHandler时需要规范消息类型&lt;T&gt;，一般是ByteBuf。 当使用ChannelInboundHandlerAdapter时要注意在接受完消息后，应该把msg手动释放掉，而SimpleChannelInboundHandler已经帮助你做了这个事情。 使用方法:ReferenceCountUtil.release(msg);进行释放，其实只要是使用了ByteBuf，都要进行这个操作，这里的原因主要涉及netty对于堆外内存的使用了，有兴趣的可以自行百度。 我们可以根据头部区分消息类型，根据类型不同进行不同的逻辑处理方法。 假如你有类似数组、Hash表存取的操作，最好把逻辑处理这部分操作放到内存队列中去处理。 netty虽然是全异步的，但是你的服务端却并不是，假如你有类似数组、Hash表存取的操作，还是应该放到队列中去，或者你应该把这里所有操作Jvm内存数据结构的操作都改成线程安全的。 ps:这里用的内存队列是Disruptor,还挺好用的，以后会写一篇关于disruptor的总结。 所有处理逻辑放入队列有好处也有坏处，当你真的这么干的时候，有可能线上服务器环境会显示你的netty很稳定，cpu开销等等都比较理想，然而事实上很可能并非如此。 一个channel从注册到断开的顺序到底是怎样的 1) channelRegistered 2) channelActive 3) channelInactive 4) channelUnregistered 超时处理userEventTriggered 到底应该咋处理： 超时策略可以处理一些客户端网络突然断开时的问题netty可以设置客户端通信时间——读超时，写超时以及读写超时当发生该类超时的时候，我们就可以在服务端进行主动把channel踢掉线的这种操作。下文中详细写~ 3.持有合法channel以及发送消息 当客户端在建立连接之后，经过了一系列认证判断啥的过程，一个合法的长连接应该被合理的引用起来，方便进行下一步的业务逻辑操作。 ChannelHandlerContext可以被理解为一个socket的上下文，拿到了它，就掌握了这个连接的通信。 so，可以放到hash中，数组中，或者跟其他客户端属性一起封装到一个类中，都可以。。。。 单发消息 ChannelHandlerContext.writeAndFlush() 单发消息回调 可能有些聪明的小朋友发现ChannelHandlerContext.writeAndFlush()返回的结果是一个channelFuture 回调类， 就天真的以为可以使用channelFuture.isSuccess() 方法验证这条消息是否真的给对方发送过去了。 NO,isSuccess只回调成功放置消息至tcp缓冲区！！！ 也就是说即便是客户端直接断网，服务端这里发送消息后拿到的 success 依旧是 true 那特么怎么判断发送消息是否成功？ 一种思路是通过判断 Channel 上绑定的时间与当前时间只差是否超过了阈值，具体的实现我会以后整理一下。 群发消息广播 有的时候业务并不单单仅仅要求点对点发送，而是很多人同时收到某个消息，比如游戏中位置的移动，这是要同时告知所有场景内用户的。 使用 ChannelGroup 1234ChannelGroup channels =new DefaultChannelGroup(GlobalEventExecutor.INSTANCE);// 这相当于把这个连接放置到这个场景中channels.add(你自己的channel)channels.writeAndFlush(); 就酱 4.超时策略的处理方式及注意事项 使用IdleStateHandler 1234567891011121314151617181920212223242526public class TcpProtocolInitalizer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); // 这里的“30,30，60”分别代表读超时，写超时以及读写超时时间，单位是秒 pipeline.addLast(&quot;ping&quot;, new IdleStateHandler(30, 30, 60, TimeUnit.SECONDS)); // 这段代码主要是声名结尾关键字，这样netty方便对多条指令进行拆包 byte[] bytes = new byte[2]; bytes[0] = (byte)0xFF; bytes[1] = (byte)0xFF; ByteBuf delimeter = Unpooled.copiedBuffer(bytes); try &#123; // 这里使用了DelimiterBasedFrameDecoder这个拆包器，也有String类型的等等 pipeline.addLast(new DelimiterBasedFrameDecoder(1024, delimeter)); int port = ch.localAddress().getPort(); System.out.println(&quot;ch.localAddress().getPort()==&quot; + port); if (port == tcpConfig.getTcpPort()) &#123; // 我们在这里关联自己的逻辑channelHandler业务 pipeline.addLast(&quot;handler&quot;, serverHandler); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 这个类要在ServerBootstrap 启动之前注入initChannel()方法里，这样就会在handler中在userEventTriggered中收到超时的回调了。 5.拆包/粘包 处理思路6.客户端异常情况的重连方式7.如何使用netty开发websocket端8.如何用客户端代码搞jmeter测试高访问量下服务端抗压能力9.netty 多服务端的开发思路10.剩下的一些坑（crc8）","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://sunjx93.com/tags/Java/"},{"name":"netty","slug":"netty","permalink":"http://sunjx93.com/tags/netty/"}]},{"title":"Cas 单点登录相关","slug":"cas","date":"2018-06-03T08:52:09.000Z","updated":"2019-03-25T01:51:03.779Z","comments":true,"path":"2018/06/03/cas/","link":"","permalink":"http://sunjx93.com/2018/06/03/cas/","excerpt":"这几天换了工作，事情一下子多了起来，前公司十分给力的只给了我400多的应付职工薪酬，心态炸了。不说别的，这几天重点研究了cas的单点登录，总结一下。","text":"这几天换了工作，事情一下子多了起来，前公司十分给力的只给了我400多的应付职工薪酬，心态炸了。不说别的，这几天重点研究了cas的单点登录，总结一下。 CAS - Central Authentication Service CAS是一个单点登录框架，通俗理解为一个应用登录了，其他被授权的应用不用再登录。 比如，A系统登录了之后，B系统就可以跳过登录，转而进入系统内。于是问题来了：在实现cas单点登录之前，我首先要实现两个系统的多数据源配置，把登录相关表设为一个共有的数据源。关于多数据源配置我另起了一篇○|￣|_ 事实上，使用cas单点登录时，相当于跳过原项目的登录过程，把登录的功能转嫁给cas服务器来实现。 1.下载由于cas是开源的，所以直接在官网 下载源码就可以。下载下来是这样子的： 其实只需要用到一个包，就可以实现简单的单点登录：cas-server-core，并且这个包下源码的编译文件最后是要放到应用服务器里面的。 把\\cas-server-4.0.0\\modules 文件夹下的cas-server-webapp-4.0.0.war改名为cas.war，并放在tomcat目录下webapps中，并启动tomcat。 此时webapps目录下已经解压了cas文件夹，可以进行下一步了。 2.对cas-server-core 源码进行修改 由于不同的项目都有着自己的密码加密规则，所以需要对cas-server-core包下的源码进行修改： 上代码： 修改\\webapps\\cas\\WEB-INF下的deployerConfigContext.xml 替换primaryAuthenticationHandler 的 bean12345&lt;bean id=&quot;primaryAuthenticationHandler&quot; class=&quot;com.distinct.cas.jdbc.QueryDatabaseAuthenticationHandler&quot;p:dataSource-ref=&quot;dataSource&quot;p:passwordEncoder-ref=&quot;passwordEncoder&quot;p:sql=&quot;select password from sys_user where username=? and status = 1&quot; /&gt; 新增123456789101112&lt;bean id=&quot;dataSource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot; &gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://192.168.0.107:3306/sys_blueroc_db?autoReconnect=true&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;passwordEncoder&quot; class=&quot;org.jasig.cas.authentication.handler.DefaultPasswordEncoder&quot; c:encodingAlgorithm=&quot;MD5&quot; p:characterEncoding=&quot;UTF-8&quot; /&gt; bean dataSource主要是定义连接用户表数据库的配置，QueryDatabaseAuthenticationHandler类就是对用户校验的处理类,在server-core 源码包中新增： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package com.distinct.cas.jdbc;import org.jasig.cas.authentication.HandlerResult;import org.jasig.cas.authentication.PreventedException;import org.jasig.cas.authentication.UsernamePasswordCredential;import org.jasig.cas.authentication.handler.support.AbstractUsernamePasswordAuthenticationHandler;import org.jasig.cas.authentication.principal.SimplePrincipal;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.jdbc.datasource.DriverManagerDataSource;import org.springframework.stereotype.Component;import javax.security.auth.login.FailedLoginException;import java.security.GeneralSecurityException;/** * @author sunjx * @date 2018/5/28 16:23 **/@Component(value = &quot;primaryAuthenticationHandler&quot;)public class QueryDatabaseAuthenticationHandler extends AbstractUsernamePasswordAuthenticationHandler&#123; private Logger logger = LoggerFactory.getLogger(QueryDatabaseAuthenticationHandler.class); @Autowired private DriverManagerDataSource dataSource; // 注入deployerConfigContext.xml 的查询sql @Autowired private String sql; /** * Authenticates a username/password credential by an arbitrary strategy. * * @param transformedCredential the credential object bearing the transformed username and password. * @return HandlerResult resolved from credential on authentication success or null if no principal could be resolved * from the credential. * @throws GeneralSecurityException On authentication failure. * @throws PreventedException On the indeterminate case when authentication is prevented. */ protected final HandlerResult authenticateUsernamePasswordInternal(final UsernamePasswordCredential transformedCredential) throws GeneralSecurityException, PreventedException &#123; //UsernamePasswordCredential参数包含了前台页面输入的用户信息 String username = getPrincipalNameTransformer().transform(transformedCredential.getUsername()); String password = transformedCredential.getPassword(); //认证用户名和密码是否正确 final String encryptedPassword = this.getPasswordEncoder().encode(password,username); logger.info(&quot;pwd:&quot;+encryptedPassword + &quot;////////////////////////////////////&quot;); System.out.println(&quot;pwd:&quot;+encryptedPassword + &quot;////////////////////////////////////&quot;); try &#123; JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource); if(encryptedPassword.equals(jdbcTemplate.queryForObject(sql, new Object[]&#123;username&#125;,String.class)))&#123; return createHandlerResult(transformedCredential, new SimplePrincipal(username), null); &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; throw new FailedLoginException(); &#125; public void setDataSource(DriverManagerDataSource dataSource) &#123; this.dataSource = dataSource; &#125; public DriverManagerDataSource getDataSource() &#123; return dataSource; &#125; public void setSql(String sql) &#123; this.sql = sql; &#125; public String getSql() &#123; return sql; &#125;&#125; 服务端创建安全证书： cmd 控制台进入某给文件路径（同linux） 生成证书keytool -genkey -alias cas(别名) -keyalg RSA -keystore D:/keys/smallkey（证书路径）2.导出证书keytool -export -file d:/keys/small.crt -alias smalllove -keystore d:/keys/smallkey3.导入证书到jdk中keytool -import -keystore C:\\Java\\jdk1.6.0_21\\lib\\security\\cacerts -file D:/keys/small.crt -alias cas 在客户端shiroConfig中定义cas的服务器路径 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165 public static final String loginUrl = &quot;http://localhost:8443/cas/login?service=你的项目路径&quot;; /** * 注册单点登出filter * @return */ @Bean public FilterRegistrationBean singleSignOutFilter()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setName(&quot;singleSignOutFilter&quot;); bean.setFilter(new SingleSignOutFilter()); bean.addUrlPatterns(&quot;/*&quot;); bean.setEnabled(true); //bean.setOrder(Ordered.HIGHEST_PRECEDENCE); return bean; &#125; /** * 定义casfilter继承`org.apache.shiro.cas.CasFilter` * * @return * @author * @create */ @Bean(name = &quot;casFilter&quot;) public CasFilter getCasFilter() &#123; MyCasFilter casFilter = new MyCasFilter(); casFilter.setName(&quot;casFilter&quot;); casFilter.setEnabled(true); casFilter.setLoginUrl(casLoginUrl); casFilter.setSuccessUrl(loginSuccessUrl); // 登录失败后跳转的URL，也就是 Shiro 执行 CasRealm 的 doGetAuthenticationInfo 方法向CasServer验证tiket casFilter.setFailureUrl(loginUrl);// 我们选择认证失败后再打开登录页面 return casFilter; &#125; /** * 该过滤器负责用户的认证工作，必须启用它 * @return */ @Bean public FilterRegistrationBean casAuthenticationFilter() &#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.setFilter(new AuthenticationFilter());// AuthenticationFilter t = new AuthenticationFilter(); filterRegistrationBean.addUrlPatterns(&quot;/*&quot;); filterRegistrationBean.addInitParameter(&quot;casServerLoginUrl&quot;,ShiroConfig.casLoginUrl); //cas 服务器登录 filterRegistrationBean.addInitParameter(&quot;serverName&quot;,ShiroConfig.shiroServerUrlPrefix); // 客户端服务器地址 return filterRegistrationBean; &#125; /** * 该过滤器负责对Ticket的校验工作，必须启用它 * @return */ @Bean public FilterRegistrationBean casFilterRegistrationBean() &#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.addUrlPatterns(&quot;/*&quot;); filterRegistrationBean.setFilter(new Cas20ProxyReceivingTicketValidationFilter()); filterRegistrationBean.addInitParameter(&quot;serverName&quot;,ShiroConfig.shiroServerUrlPrefix); // cas 服务器地址 filterRegistrationBean.addInitParameter(&quot;casServerUrlPrefix&quot;,ShiroConfig.casServerUrlPrefix); // 客户端服务器地址 return filterRegistrationBean; &#125; /** * 该过滤器负责实现HttpServletRequest请求的包裹， * 比如允许开发者通过HttpServletRequest的getRemoteUser()方法获得SSO登录用户的登录名 * 可选配置 * @return */ @Bean public FilterRegistrationBean httpServletRequestWrapperFilter() &#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.addUrlPatterns(&quot;/*&quot;); filterRegistrationBean.setFilter(new HttpServletRequestWrapperFilter()); return filterRegistrationBean; &#125; /** * 该过滤器使得开发者可以通过org.jasig.cas.client.util.AssertionHolder来获取用户的登录名。 * AssertionHolder.getAssertion().getPrincipal().getName()。 * @return */ @Bean public FilterRegistrationBean assertionThreadLocalFilter() &#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.addUrlPatterns(&quot;/*&quot;); filterRegistrationBean.setFilter(new AssertionThreadLocalFilter()); return filterRegistrationBean; &#125; /** * 注册单点登出listener * @return */ @Bean public ServletListenerRegistrationBean singleSignOutHttpSessionListener()&#123; ServletListenerRegistrationBean bean = new ServletListenerRegistrationBean(); bean.setListener(new SingleSignOutHttpSessionListener());// bean.setName(&quot;&quot;); //默认为bean name bean.setEnabled(true); //bean.setOrder(Ordered.HIGHEST_PRECEDENCE); //设置优先级 return bean; &#125; // 然后声明shiro 的cas登录的realm @Bean public MyShiroCasRealm myShiroCasRealm(EhCacheManager cacheManager) &#123; MyShiroCasRealm realm = new MyShiroCasRealm (); realm.setCacheManager(cacheManager); return realm; &#125; // 在返回SecurityManager的bean内加入MyShiroCasRealm： @Bean public SecurityManager securityManager() &#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); Collection collection = new ArrayList(); ((ArrayList) collection).add(userRealm()); ((ArrayList) collection).add(myShiroCasRealm(ehCacheManager())); //设置realm. securityManager.setRealms(collection); // 自定义缓存实现 使用redis if (Constant.CACHE_TYPE_REDIS.equals(cacheType)) &#123; securityManager.setCacheManager(cacheManager()); &#125; else &#123; securityManager.setCacheManager(ehCacheManager()); &#125; securityManager.setSessionManager(sessionManager()); return securityManager; &#125; &lt;!-- 最后，加入上面已经声明的过滤器 --&gt; @Bean ShiroFilterFactoryBean shiroFilterFactoryBean(SecurityManager securityManager) &#123; Map&lt;String, Filter&gt; filters = new HashMap&lt;&gt;(); filters.put(&quot;casFilter&quot;, getCasFilter()); filters.put(&quot;authenticationFilter&quot;, casAuthenticationFilter().getFilter()); filters.put(&quot;cas20ProxyReceivingTicketValidationFilter&quot;, casFilterRegistrationBean().getFilter()); filters.put(&quot;httpServletRequestWrapperFilter&quot;, httpServletRequestWrapperFilter().getFilter()); filters.put(&quot;assertionThreadLocalFilter&quot;, assertionThreadLocalFilter().getFilter()); ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); shiroFilterFactoryBean.setSecurityManager(securityManager); shiroFilterFactoryBean.setLoginUrl(loginUrl); shiroFilterFactoryBean.setSuccessUrl(loginSuccessUrl); shiroFilterFactoryBean.setUnauthorizedUrl(unauthorizedUrl); shiroFilterFactoryBean.setFilters(filters); LinkedHashMap&lt;String, String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;&gt;(); filterChainDefinitionMap.put(&quot;/css/**&quot;, &quot;anon&quot;); filterChainDefinitionMap.put(&quot;/api/**&quot;, &quot;anon&quot;); filterChainDefinitionMap.put(&quot;/**&quot;, &quot;authc&quot;); shiroFilterFactoryBean.setFilterChainDefinitionMap(filterChainDefinitionMap); return shiroFilterFactoryBean; &#125; 编译server-core 源码，放在tomcat-8.5.30\\webapps\\cas\\WEB-INF\\classes下 然后，可以试着运行一下tomcat，期间可能会有依赖包确实，把下载的jar包放到tomcat-8.5.30\\webapps\\cas\\WEB-INF\\lib 下。 如果访问http://localhost:8443/cas/login 出现如下页面，则证明部署成功了。 2.cas 修改登录样式假如，你觉得上面的登录样式太丑了（事实上的确很丑..），那我们可以去修改一下登录的样式： 算了，贴个链接吧，我太懒了QAQ cas4.2.7定制登录页面样式(并且让页面默认使用中文提示)","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://sunjx93.com/tags/Java/"},{"name":"CAS单点登录","slug":"CAS单点登录","permalink":"http://sunjx93.com/tags/CAS单点登录/"}]},{"title":"Mysql 分页整理","slug":"fenye","date":"2018-04-10T05:52:09.000Z","updated":"2018-04-24T08:39:10.201Z","comments":true,"path":"2018/04/10/fenye/","link":"","permalink":"http://sunjx93.com/2018/04/10/fenye/","excerpt":"轻量数据与大量数据的分页完全是两回事，如果没有很好地进行优化，很可能会导致性能的直线下降。现在对mysql分页做一个简单的小整理…","text":"轻量数据与大量数据的分页完全是两回事，如果没有很好地进行优化，很可能会导致性能的直线下降。现在对mysql分页做一个简单的小整理… 最简单的分页 select * from content order by id desc limit 0, 10 当数据量多了一些的时候：select * from content order by id desc limit 1000000, 10 当数据量比较大的时候，这样分页的方案会导致最后几页的查询速度下降。 所以SELECT * FROM table WHERE id &gt;= (SELECT id FROM table LIMIT 1000000, 1) LIMIT 10; 因为id是拥有索引的主键，所以，效率会比纯limit高一些 什么是更优解？SELECT * FROM table WHERE id BETWEEN 1000000 AND 1000010; 另：如果找寻的id并不连续，可以先找出id，再用in的方式查询： SELECT * FROM table WHERE id IN(10000, 100000, 1000000...); 另一种方式： FOUND_ROWS() 使用MySql中的函数FOUND_ROWS()，在SELECT中可以得到两个结果： 得到Limit的内容 得到去除Limit以后所有行数 SELECT语句中经常可能用LIMIT限制返回行数。有时候可能想要知道如果没有LIMIT会返回多少行，但又不想再执行一次相同语句。那么，在SELECT查询中包含SQL_CALC_FOUND_ROWS选项，然后执行FOUND_ROWS()就可以了： select SQL_CALC_FOUND_ROWS * FROM tbl_name WHERE id &gt; 100 LIMIT 10; SELECT FOUND_ROWS(); 如果在前一条语句中使用SQL_CALC_FOUND_ROWS选项，FOUND_ROWS()将返回第一条语句没有LIMIT时返回的行数。 如果在前一条语句中没有使用SQL_CALC_FOUND_ROWS选项，FOUND_ROWS()将返回前一条语句实际返回的行数。 如果使用 SELECT SQL_CALC_FOUND_ROWS，MySQL必须计算所有结果集的行数。尽管这样，总比再执行一次不使用LIMIT的查询要快多了吧，因为那样结果集要返回客户端滴。（另外：应该不单是没有将结果集返回的原因，还有原因可能是比如LIKE之类比较费劲的SQL不需要再去劳累一次。） – 注意下面语句中的条件 LIKE SELECT SQL_CALC_FOUND_ROWS * FROM tbl_name WHERE Name LIKE ‘%string%’ id &gt; 100 LIMIT 10; SELECT FOUND_ROWS(); – 上面语句等价于下面语句，但性能方面应该提升非常非常的明显： SELECT COUNT(*) FROM tbl_name WHERE Name LIKE ‘%string%’ ; SELECT * FROM tbl_name WHERE Name LIKE ‘%string%’ id &gt; 100 LIMIT 10;","categories":[],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://sunjx93.com/tags/Mysql/"}]},{"title":"Bean 生命周期","slug":"LifeBean","date":"2018-04-07T08:52:09.000Z","updated":"2018-04-24T09:16:54.629Z","comments":true,"path":"2018/04/07/LifeBean/","link":"","permalink":"http://sunjx93.com/2018/04/07/LifeBean/","excerpt":"Spring Bean 的生命周期在面试中被问到不止一次了，每次结结巴巴的说出来好没面子呀~","text":"Spring Bean 的生命周期在面试中被问到不止一次了，每次结结巴巴的说出来好没面子呀~ Spring Bean 作用域、生命周期Bean的作用域 Spring 3中为Bean定义了5中作用域，分别为singleton（单例）、prototype（原型）、request、session和global session，5种作用域说明如下： singleton：单例模式，Spring IoC容器中只会存在一个共享的Bean实例，无论有多少个Bean引用它，始终指向同一对象。Singleton作用域是Spring中的缺省（默认）作用域，也可以显示的将Bean定义为singleton模式，配置为： 1&lt;bean id=&quot;userDao&quot; class=&quot;com.ioc.UserDaoImpl&quot; scope=&quot;singleton&quot;/&gt; prototype:原型模式，每次通过Spring容器获取prototype定义的bean时，容器都将创建一个新的Bean实例，每个Bean实例都有自己的属性和状态，而singleton全局只有一个对象。根据经验，对有状态的bean使用prototype作用域，而对无状态的bean使用singleton作用域。 request：在一次Http请求中，容器会返回该Bean的同一实例。而对不同的Http请求则会产生新的Bean，而且该bean仅在当前Http Request内有效。 1&lt;bean id=&quot;loginAction&quot; class=&quot;com.cnblogs.Login&quot; scope=&quot;request&quot;/&gt; 针对每一次Http请求，Spring容器根据该bean的定义创建一个全新的实例，且该实例仅在当前Http请求内有效，而其它请求无法看到当前请求中状态的变化，当当前Http请求结束，该bean实例也将会被销毁。 session：在一次Http Session中，容器会返回该Bean的同一实例。而对不同的Session请求则会创建新的实例，该bean实例仅在当前Session内有效。1&lt;bean id=&quot;userPreference&quot; class=&quot;com.ioc.UserPreference&quot; scope=&quot;session&quot;/&gt; 同Http请求相同，每一次session请求创建新的实例，而不同的实例之间不共享属性，且实例仅在自己的session请求内有效，请求结束，则实例将被销毁。 global Session：在一个全局的Http Session中，容器会返回该Bean的同一个实例，仅在使用portlet context时有效。 Bean的生命周期 Spring容器可以管理singleton作用域下Bean的生命周期，在此作用域下，Spring能够精确地知道Bean何时被创建，何时初始化完成，以及何时被销毁。 对于prototype作用域的Bean，Spring只负责创建，当容器创建了Bean的实例后，Bean的实例就交给了客户端的代码管理，Spring容器将不再跟踪其生命周期，并且不会管理那些被配置成prototype作用域的Bean的生命周期 Bean的生命周期： 1、实例化一个Bean－－也就是我们常说的new 2、按照Spring上下文对实例化的Bean进行配置－－也就是IOC注入； 3、如果这个Bean已经实现了BeanNameAware接口，会调用它实现的setBeanName(String)方法，此处传递的就是Spring配置文件中Bean的id值 4、如果这个Bean已经实现了BeanFactoryAware接口，会调用它实现的setBeanFactory(setBeanFactory(BeanFactory)传递的是Spring工厂自身（可以用这个方式来获取其它Bean，只需在Spring配置文件中配置一个普通的Bean就可以）； 5、如果这个Bean已经实现了ApplicationContextAware接口，会调用setApplicationContext(ApplicationContext)方法，传入Spring上下文（同样这个方式也可以实现步骤4的内容，但比4更好，因为ApplicationContext是BeanFactory的子接口，有更多的实现方法）； 6、如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessBeforeInitialization(Object obj, String s)方法，BeanPostProcessor经常被用作是Bean内容的更改，并且由于这个是在Bean初始化结束时调用那个的方法，也可以被应用于内存或缓存技术；主要是我们如果需要在spring中增加自己的逻辑 7、如果Bean在Spring配置文件中配置了init-method属性会自动调用其配置的初始化方法。 8、如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessAfterInitialization(Object obj, String s)方法； 注：以上工作完成以后就可以应用这个Bean了，那这个Bean是一个Singleton的，所以一般情况下我们调用同一个id的Bean会是在内容地址相同的实例，当然在Spring配置文件中也可以配置非Singleton，这里我们不做赘述。 9、当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，会调用那个其实现的destroy()方法； 10、最后，如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的销毁方法。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://sunjx93.com/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://sunjx93.com/tags/Spring/"}]},{"title":"自定义注解","slug":"annotation","date":"2018-04-07T08:52:09.000Z","updated":"2018-04-24T09:16:34.535Z","comments":true,"path":"2018/04/07/annotation/","link":"","permalink":"http://sunjx93.com/2018/04/07/annotation/","excerpt":"自定义注解的用法，会了的话定义一个@Override同名注解什么的…","text":"自定义注解的用法，会了的话定义一个@Override同名注解什么的… 1.首先要了解自定义注解的两个元素（元注解） 用来声明注解本身的行为 @Target 用来声明注解可以被添加在哪些类型的元素上,如类型、方法和域等。 传入参数|描述–|–TYPE|METHOD|CONSTRUCTOR |FIELD| @Retention : 声明注解的保留策略 关键字|描述 –|– CLASS|声明注解保存在类文件 RUNTIME|声明注解保存在JVM运行时 SOURCE|声明注解保存在源码中 @Documented 指明拥有这个注解的元素可以被javadoc此类的工具文档化。这种类型应该用于注解那些影响客户使用带注释的元素声明的类型。如果一种声明使用Documented进行注解，这种类型的注解被作为被标注的程序成员的公共API。 @Inherited 指明该注解类型被自动继承。如果用户在当前类中查询这个元注解类型并且当前类的声明中不包含这个元注解类型，那么也将自动查询当前类的父类是否存在Inherited元注解，这个动作将被重复执行知道这个标注类型被找到，或者是查询到顶层的父类。 Java内建注解Java提供了三种内建注解。 @Override 当我们想要复写父类中的方法时，我们需要使用该注解去告知编译器我们想要复写这个方法。这样一来当父类中的方法移除或者发生更改时编译器将提示错误信息。 @Deprecated 当我们希望编译器知道某一方法不建议使用时，我们应该使用这个注解。Java在javadoc 中推荐使用该注解，我们应该提供为什么该方法不推荐使用以及替代的方法。 @SuppressWarnings 这个仅仅是告诉编译器忽略特定的警告信息，例如在泛型中使用原生数据类型。它的保留策略是SOURCE,并且被编译器丢弃。2.开始 a.以此在类中声明一个自定义注解@Retention(RetentionPolicy.RUNTIME) @Target(ElementType.FIELD) public @interface AnnotationDemo { // 声明一个注解 String name(); int age() default 0; } 其中，finished这个注解的默认值是0,也就是可以设置默认值！ b.在某项中注入值public class AnnotationPriv { @AnnotationDemo(name = &quot;Tom&quot;,age = 19) private String id; } c.设置注解的逻辑处理public class AnnotationUtilDemo { public static void getFruitInfo(Class&lt;?&gt; clazz){ String personName =&quot;名称：&quot;; String personAge = &quot;年龄&quot;; Field[] fields = clazz.getDeclaredFields(); for(Field field :fields){ if(field.isAnnotationPresent(AnnotationDemo.class)){ AnnotationDemo annotationDemo = (AnnotationDemo) field.getAnnotation(AnnotationDemo.class); personName = personName+annotationDemo.name(); personAge = personAge + annotationDemo.age(); System.out.println(personName); System.out.println(personAge); } } } } d.运行 public static void main(String[] args) { AnnotationUtilDemo.getFruitInfo(AnnotationPriv.class); } e.得出结果名称：Tom 年龄19","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://sunjx93.com/tags/Java/"},{"name":"Annotation","slug":"Annotation","permalink":"http://sunjx93.com/tags/Annotation/"}]},{"title":"Linux 下oracle的数据恢复以及数据库命令行安装","slug":"linux_oracle","date":"2017-11-07T08:52:09.000Z","updated":"2018-04-24T09:17:02.507Z","comments":true,"path":"2017/11/07/linux_oracle/","link":"","permalink":"http://sunjx93.com/2017/11/07/linux_oracle/","excerpt":"由于项目在运行过程中所需的空间越来越大，最终Linux的表分区使用比例达到了100%，导致项目无法正常登录以及无法正常访问数据库，原因主要是表空间过大。在备份了dbf文件后之后，由于操作有误，误删了oracle的一个redo日志，于是不得不重装oracle 因为表空间主要存储的都是用户上传的文件数据，所以必须恢复","text":"由于项目在运行过程中所需的空间越来越大，最终Linux的表分区使用比例达到了100%，导致项目无法正常登录以及无法正常访问数据库，原因主要是表空间过大。在备份了dbf文件后之后，由于操作有误，误删了oracle的一个redo日志，于是不得不重装oracle 因为表空间主要存储的都是用户上传的文件数据，所以必须恢复 ps: 因为服务器上相关的配置文件都配置过一遍，所以不用重新配置 1. 把dbf文件通过恢复工具导入到测试环境在网上找了好多数据库恢复的软件，但都是收费的…QAQ 最后选择一个叫odu的工具，非图形化界面，需要注意的是配置文件的格式需要规范一点，具体的操作步骤可以看： 老熊的博客 再贴一个odu的下载 总之经过一番操作之后终于把数据跑到自己电脑上了，随后我们要进行的是linux在oracle的命令行安装。 2. oracle 静默安装 由于这个项目的运行环境是内网环境，所以一些yum什么的工具都暂时用不了，当时也没有什么时间去鼓捣图形化之类的东西了，就试着用xshell进行了命令行安装。 a. 下载oracle for linux 的zip安装包上传到机器上并解压，要注意文件的权限不能是root，应该是oracle，也就是用作数据库的权限账号 b. 使用oracle用户登录并解压到一个目录下 unzip filenamec. 解压完之后会有一个database目录我们要找到/oracle/database/response下的三个.rsp 文件，复制到/home/oracle里面，并在这里做一些修改。 首先 是db_install.rsp,这里的改动需要仔细，如果配置错误的话就会报错。 静默安装_db-install.rsp 配置 接下来是dbca.rsp和netca.rsp dbca.rspvi dbca.rsp 修改以下内容 GDBNAME = “ora11g” SID = “ora11g” SYSPASSWORD = “oracle11” SYSTEMPASSWORD = “oracle11” netca.rspvi netca.rsp修改以下内容 INSTALL_TYPE=””custom”” 配置完之后进入database目录下，执行脚本1./runInstaller -silent -responseFile /home/oracle/db_install.rsp 如果一切顺利的话，会提示你the setup completed 之类的，而且会提示你运行两个文件，注意: 这两个文件需要用root用户运行。 运行完成后，可能要退回oracle 的主目录刷新一下.bash_profile1source .bash_profile 成功后就可以看到登录信息里有自己的sid了，这个时候就是常规操作： 12345创建数据库 dbca -silent -cloneTemplate -responseFile ./dbca.rsp创建监听 netca /silent /responseFile /home/oracle/netca.rsp开启oracle监听 lsnrctl start 3 创建oracle 实例 安装好oracle 之后是没有oracle实例的，需要自己去建 创建oracle实例（没错我在偷懒） 总之最后很幸运的没有丢数据，我们一定要做好的是备份！备份！备份！","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://sunjx93.com/tags/Linux/"},{"name":"Oracle","slug":"Oracle","permalink":"http://sunjx93.com/tags/Oracle/"}]},{"title":"Quartz实现定时任务","slug":"Quartz","date":"2017-07-07T08:52:09.000Z","updated":"2018-04-24T09:17:11.840Z","comments":true,"path":"2017/07/07/Quartz/","link":"","permalink":"http://sunjx93.com/2017/07/07/Quartz/","excerpt":"Quartz 最近公司项目中用到了定时任务提醒的功能，Timer在功能上已经无法很好的满足业务，来学习一下Quartz","text":"Quartz 最近公司项目中用到了定时任务提醒的功能，Timer在功能上已经无法很好的满足业务，来学习一下Quartz Quartz 的生命周期 Job接口在execute（JobExecation…）{}中编写逻辑 调用器 执行Job时创建的Job实例，调用完成时，job实例会被释放并回收 JobDetail属性 name 任务名称 group 任务组 默认DEFAULT jobclass jobDetailMap 作用是在execute中传递参数，一般为基本数据类型 ...... JobDataMap&amp;TriggerDataMap: 强力的map型参数，由quzrtz封装，同时实现了map接口 关于Quzrtz的Trigger 作为Quartz的触发器来执行JobTrigger的通用属性 Job Key： 获取JobDetail的key值 startTime： 触发器首次触发的时间 endTime： …停止时间 SimpleTrigger&amp; CronTriggerSimpleTrigger： SimpleTrigge有点类似Java中Timer的一个变体，但是个人觉得在逻辑上比Timer要来的简便 CronTrigger： CronTrigger是Quartz的核心，是一种基于日历的作业调度器 重点： cron表达式：用来配置CronTrigger实例 由7个子表达式组成,描述了时间表的详细信息 格式： [秒] [分] [小时] [日] [月] [年] 注意 []之间有空格符 事例 1234567891011121314151617181920JobDetail jobDetail = JobBuilder.newJob(QuartzJob.class) .withIdentity(&quot;myJob&quot;).build();CronTrigger trigger = (CronTrigger) TriggerBuilder .newTrigger() .withIdentity(&quot;myTrigger&quot;, &quot;group1&quot;) .withSchedule( CronScheduleBuilder.cronSchedule(&quot;* * * * * ?&quot;)) .build();// 创建Scheduler实例SchedulerFactory sfact = new StdSchedulerFactory();Scheduler scheduler = sfact.getScheduler();scheduler.start();System.out.println(&quot;scheduled time is :&quot; + sf.format(scheduler.scheduleJob(jobDetail, trigger)));//scheduler执行两秒后挂起Thread.sleep(2000L);//shutdown(true)表示等待所有正在执行的job执行完毕之后，再关闭scheduler//shutdown(false)即shutdown()表示直接关闭schedulerscheduler.shutdown(false);System.out.println(&quot;scheduler is shut down? &quot; + scheduler.isShutdown()); 其中CronScheduleBuilder.cronSchedule(&quot;* * * * * ?&quot;))这句就是Cron表达式的用法 关于Cron表达式的字符含义: 字段 是否必填 允许值 允许的特殊字符 秒 是 0-59 , - * / 分 是 0-59 , - * / 小时 是 0-23 , - * / 日 是 1-31 , - * ? / L W C 月 是 1-12或者JAN-DEC , - * / 周 是 1-7或者SUN-SAT ,- * ? / L C # 年 否 empty,1970-2099 , - * / 特殊字符 含义 , 表示或 的意思 - 至某事某刻，between的关系 * 表示每， / 表示每隔某时间段触发，比如分的写法:0/5 表示每隔5分钟触发，5/20代表每五分钟触发一次，25,45各触发一次 ? 表示无所谓，不关注，无关紧要 # 第的意思，如6#3每月第三周星期五触发，6代表周五 L 代表最后一 的意思 W 表示有效工作日（周一到周五）， L与W可连用，表示某月最后一个工作日 关于周的换算：1代表周日，6代表周五，以此类推类推 如：0 15 10 ? * 6L 2016-2017: 2016-2017年每月最后一周的周五10点15分执行 年可以不填QAQ ###SchedulerFactory 用来工厂模式来创建Schedular StdSchedulerFactory利用.getScheduler();方法初始创建调度器，参数配置可以采用quartz。properties方法 比较Timer1.无法并发执行：Timer不怎么支持并发 2.因为Timer有且仅有一个后台执行的线程，若一旦爆出RunTimeException，则会停止所有的任务执行 瓶颈：a) 对时效性要求较高的多任务并发作业，虽然支持多任务，但是毕竟是串行接口 b) 对复杂任务的调度不足，不支持定时任务 Quartz1.精细控制流程 2.支持若干任务在上面执行 a)调度功能 b) 持久化机制，数据不会丢失 c) 分布&amp;集群功能","categories":[],"tags":[{"name":"Quartz","slug":"Quartz","permalink":"http://sunjx93.com/tags/Quartz/"},{"name":"Timer","slug":"Timer","permalink":"http://sunjx93.com/tags/Timer/"}]},{"title":"SpringData相关","slug":"sd","date":"2017-05-27T08:52:09.000Z","updated":"2017-05-31T05:53:27.405Z","comments":true,"path":"2017/05/27/sd/","link":"","permalink":"http://sunjx93.com/2017/05/27/sd/","excerpt":"SpringData是原先工作用到了的东西，提供一个一致性的，基于spring的项目，用来访问数据（访问数据库），现在来半预习半复习一下","text":"SpringData是原先工作用到了的东西，提供一个一致性的，基于spring的项目，用来访问数据（访问数据库），现在来半预习半复习一下 特点 可以访问关系型数据库，也可以访问非关系型数据库 目的 减少数据访问层的开发量 其实只需要声明一个持久层的接口 springData 包含的子项目 Spring Data JPA Spring Data MongoDB Spring Data Redis Spring Data Solr (一个全文搜索的东西) 等等….. 1.传统方式访问数据库 jdbc get connection get statement resultSet a)添加依赖123456789101112&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.38&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.10&lt;/version&gt; &lt;/dependency&gt; b)开发JDBCUtil 工具类获取connection 12345678910111213141516171819/** * 获取connection * @return */public static Connection getConnection() throws Exception &#123; //获取配置文件的方法，db.properties 是设置好的配置文件 InputStream input = JDBCUtil.class.getClassLoader().getResourceAsStream(&quot;db.properties&quot;); Properties properties = new Properties(); properties.load(input); String url = properties.get(&quot;jdbc.url&quot;).toString(); String username = properties.get(&quot;jdbc.username&quot;).toString(); String driverClass = properties.get(&quot;user.driverClass&quot;).toString(); Class.forName(driverClass); Connection conn= DriverManager.getConnection(url, username, &quot;&quot;); return conn;&#125; db.properties,灰色的就是没有使用过的 1234user.driverClass = com.mysql.jdbc.Driveruser.username= rootuser.url=jdbc:mysql:///localhostuser.password = 使用 springData jdbc 模板访问数据库 c) DAO 层开发 真的是好复古好复古的写法，DaoImpl1234567891011121314151617181920212223242526272829303132333435/** * 传说中的经典写法？？？？ * @return */ public List&lt;Student&gt; selectAllStudents() &#123; Connection conn = null; PreparedStatement preparedStatement =null; ResultSet resultSet=null; List&lt;Student&gt; li = new ArrayList&lt;Student&gt;(); String sql = &quot;select id ,name,age from tb_student &quot;; Student student = null; try &#123; conn = JDBCUtil.getConnection(); preparedStatement = conn.prepareStatement(sql); resultSet = preparedStatement.executeQuery(); while(resultSet.next())&#123; //获取结果集中int类型的id对应的value int id = resultSet.getInt(&quot;id&quot;); String name = resultSet.getString(&quot;name&quot;); int age = resultSet.getInt(&quot;age&quot;); student = new Student(); student.setAge(age); student.setId(id); student.setName(name); li.add(student); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; JDBCUtil.release(resultSet,preparedStatement,conn); &#125; return li; &#125; 2.Spring模板方式访问数据库—-SpringTemplet 配置xml 12345678&lt;!-- dbcTermplet--&gt; &lt;bean id=&quot;jdbcTemplet&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;studentDao&quot; class=&quot;com.drazen.dao.impl.SpringJdbcDaoImpl&quot;&gt; &lt;property name=&quot;jdbcTemplate&quot; ref=&quot;jdbcTemplet&quot;/&gt; &lt;/bean&gt; 然后再dao层调用jdbcTemplet: 1234567891011121314151617181920212223242526 private JdbcTemplate jdbcTemplate; public JdbcTemplate getJdbcTemplate() &#123; return jdbcTemplate;&#125;public void setJdbcTemplate(JdbcTemplate jdbcTemplate) &#123; this.jdbcTemplate = jdbcTemplate;&#125; public List&lt;Student&gt; selectAllStudents() &#123; final List&lt;Student&gt; li = new ArrayList&lt;Student&gt;(); String sql = &quot;select id ,name,age from tb_student &quot;; jdbcTemplate.query(sql, new RowCallbackHandler() &#123; public void processRow(ResultSet resultSet) throws SQLException &#123; int id = resultSet.getInt(&quot;id&quot;); String name = resultSet.getString(&quot;name&quot;); int age = resultSet.getInt(&quot;age&quot;); Student student = new Student(); student.setAge(age); student.setId(id); student.setName(name); li.add(student); &#125; &#125;); return li; &#125; 其实这些方式代码量很多，且很重复，人力成本比较高 SpringData 方式1.开发环境：maven 依赖 12345678910111213&lt;!-- https://mvnrepository.com/artifact/org.springframework.data/spring-data-jpa --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-jpa&lt;/artifactId&gt; &lt;version&gt;1.10.5.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.hibernate/hibernate-entitymanager --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt; &lt;version&gt;5.1.0.Final&lt;/version&gt; &lt;/dependency&gt; 依赖下载完成后，就要配置bean.xml文件 在bean.xml中配置EntityManagerFactoryEntityManagerFactory是SpringData的核心之一 123456789101112131415161718&lt;bean id=&quot;entityManagerFactory&quot; class=&quot;org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;property name=&quot;jpaVendorAdapter&quot;&gt; &lt;bean class=&quot;org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter&quot;/&gt; &lt;/property&gt; &lt;property name=&quot;packagesToScan&quot; value=&quot;com.drazen&quot;/&gt; &lt;property name=&quot;jpaProperties&quot;&gt; &lt;props&gt; &lt;prop key=&quot;hibernate.ejb.naming_strategy&quot;&gt;org.hibernate.cfg.ImprovedNamingStrategy&lt;/prop&gt; &lt;prop key=&quot;hibernate.dialect&quot;&gt;org.hibernate.dialect.MySQL5InnoDBDialect&lt;/prop&gt;&lt;!--hibernate方言--&gt; &lt;prop key=&quot;hibernate.show_sql&quot;&gt;true&lt;/prop&gt;&lt;!--显示sql--&gt; &lt;prop key=&quot;hibernate.format_sql&quot;&gt;true&lt;/prop&gt;&lt;!--格式化sql--&gt; &lt;prop key=&quot;hibernate.hbm2ddl.auto&quot;&gt;update&lt;/prop&gt;&lt;!--如果没有对应表的话根据实体类生成表--&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; 然后，定义Dao层类型的接口，注意，要实现SpringData功能，首先应该extendsorg.springframework.data.repository.Repository接口或者使用@RepositoryDefinition(domainClass = Employee.class, idClass = Integer.class)注解。其中的domainClass，idClass属性是对应表的实体类与id主键。 Repository类的定义：123public interface Repository&lt;T, ID extends Serializable&gt; &#123;&#125; 1）Repository是一个空接口，标记接口没有包含方法声明的接口,其实有点像Serializable接口 2）如果我们定义的接口EmployeeRepository extends Repository 如果我们自己的接口没有extends Repository，运行时会报错：org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type ‘com.imooc.repository.EmployeeRepository’ available 3) 添加注解能到达到不用extends Repository的功能@RepositoryDefinition(domainClass = Employee.class, idClass = Integer.class) SpringData可以实现通过方法命名规范来自动生成sql进行查询，也就是说，没有方法体 下面是方法名称的命名规范。 要注意：对于按照方法命名规则来使用的话，有弊端： 方法名会比较长： 约定大于配置 对于一些复杂的查询，是很难实现 @Query是一个更好的使用定制sql的工具注解，我通常把它理解为Mybatis中的类似@Select（）酱紫的,而且，它支持命名参数以及索引参数的使用： 就是?这种参数参数插入 支持本地查询123456789101112131415161718192021@Query(&quot;select o from Employee o where id=(select max(id) from Employee t1)&quot;) public Employee getEmployeeByMaxId(); @Query(&quot;select o from Employee o where o.name=?1 and o.age=?2&quot;) public List&lt;Employee&gt; queryParams1(String name, Integer age); @Query(&quot;select o from Employee o where o.name=:name and o.age=:age&quot;) public List&lt;Employee&gt; queryParams2(@Param(&quot;name&quot;) String name, @Param(&quot;age&quot;) Integer age); @Query(&quot;select o from Employee o where o.name like %?1%&quot;) public List&lt;Employee&gt; queryLike1(String name); @Query(&quot;select o from Employee o where o.name like %:name%&quot;) public List&lt;Employee&gt; queryLike2(@Param(&quot;name&quot;) String name); @Query(nativeQuery = true, value = &quot;select count(1) from employee&quot;) public long getCount(); @Modifying @Query(&quot;update Employee o set o.age = :age where o.id = :id&quot;) public void update(@Param(&quot;id&quot;) Integer id, @Param(&quot;age&quot;) Integer age); 关于SPringData中事物 在写操作中需要事物的支持 @Modifying–允许修改 事物在SpringData中的使用 事务在Spring data中的使用： 1）事务一般是在Service层 2）@Query、 @Modifying、@Transactional的综合使用 使用： 在service层中新建service类，并调用update方法： 123456789101112131415161718192021package com.drazen.service;import com.drazen.repository.EmployeeRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import javax.transaction.Transactional;@Servicepublic class EmployeeService &#123; @Autowired private EmployeeRepository employeeRepository;// 手工加入事物注解，并在spring开启自动扫描 @Transactional public void update(Integer id, Integer age) &#123; employeeRepository.update(id, age); &#125;&#125; 关于SpringData JPA1) CrudRepository接口 这个接口其实就是针对实体进行的机械化写操作，简单粗暴快方法有这些： 12345678910111213141516171819202122//保存一个实体&lt;S extends T&gt; S save(S var1);//保存多个实体&lt;S extends T&gt; Iterable&lt;S&gt; save(Iterable&lt;S&gt; var1);//查找一个实体T findOne(ID var1);//查看某个实体记录是否存在boolean exists(ID var1);//查询所有Iterable&lt;T&gt; findAll();//根据id组查询所有结果Iterable&lt;T&gt; findAll(Iterable&lt;ID&gt; var1);//数据字段数量long count();//删除单个void delete(ID var1);//根据实体删除单个void delete(T var1);//删除一组void delete(Iterable&lt;? extends T&gt; var1);//删除所有void deleteAll(); 2)PagingAndSortingRepository 接口支持分页，排序 创建继承了PagingAndSortingRepository的interface12public interface PageRep extends PagingAndSortingRepository&lt;Employee,Integer&gt; &#123;&#125; 1234 // 返回所有实体 Iterable&lt;T&gt; findAll(Sort var1);//返回page对象 Page&lt;T&gt; findAll(Pageable var1); 使用PAGE 构建分页 1234567891011121314151617 @Autowired private PageRep pageRep; public void getPage()&#123; //import org.springframework.data.domain.PageRequest; Pageable pageable = new PageRequest(0,5); Page&lt;Employee&gt; page = pageRep.findAll(pageable);//总页数 System.out.println(page.getTotalPages());// 总记录数 System.out.println(page.getTotalElements());// 当前第几页 System.out.println(page.getNumber());// 当前页面的集合 System.out.println(page.getContent());// 当前页面的记录数 System.out.println(page.getNumberOfElements()); &#125; PageRep 是一个继承了PagingAndSortingRepository的初始interface Pageable 是来自org.springframework.data.domain.PageRequest的类 其实page.getContent()获取到的是List 排序123456789101112131415161718192021 public void getSort()&#123;// import org.springframework.data.domain.Sort.Order;// 进构造器的参数是升序或者降序，类似于order by id desc Sort.Order order = new Sort.Order(Sort.Direction.DESC,&quot;id&quot;);// import org.springframework.data.domain.Sort; Sort sort = new Sort(order);// 将构建好的sort传入PageRequest Pageable pageable = new PageRequest(0,5,sort); Page&lt;Employee&gt; page = pageRep.findAll(pageable); //总页数 System.out.println(page.getTotalPages());// 总记录数 System.out.println(page.getTotalElements());// 当前第几页 System.out.println(page.getNumber());// 当前页面的集合 System.out.println(page.getContent());// 当前页面的记录数 System.out.println(page.getNumberOfElements()); &#125; 3) JpaSpecificationExecutor 接口 其实我觉得这个方法可能还不如直接写sql，但是好像可以对原生sql有很好的支持 Specification封装了JPA Critical 的查询条件 org.springframework.data.jpa.repository目录下 新建接口继承JpaSpecificationExecutor：12public interface JpaSpecificationRepo extends JpaSpecificationExecutor&lt;Employee&gt; &#123;&#125; 组合功能，如分页+排序+查询条件 12345678910111213141516171819202122 public void testNewInterface()&#123;// 假如查询条件设定为age&gt;50 Sort.Order order = new Sort.Order(Sort.Direction.DESC,&quot;id&quot;); Sort sort = new Sort(order);// import org.springframework.data.jpa.domain.Specification; Specification&lt;Employee&gt; specification = new Specification&lt;Employee&gt;() &#123; @Override public Predicate toPredicate(Root&lt;Employee&gt; root, CriteriaQuery&lt;?&gt; criteriaQuery, CriteriaBuilder criteriaBuilder) &#123; Path path = root.get(&quot;age&quot;); /*criteriaBuilder: 构建 * root：实体 * criteriaQuery：查询条件 * * */ return criteriaBuilder.gt(path,50); &#125; &#125;; Pageable pageable = new PageRequest(0,5,sort); Page&lt;Employee&gt; page = pageRep.findAll(specification,pageable); &#125; 总结 SpringData也支持非关系型数据库 总的来说，springdata是一个可以提高开发效率的spring的工具集","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://sunjx93.com/tags/Java/"},{"name":"SpringData","slug":"SpringData","permalink":"http://sunjx93.com/tags/SpringData/"}]},{"title":"Jquery 的一些林林总总","slug":"jquery_log1","date":"2017-05-10T08:52:09.000Z","updated":"2017-05-27T08:16:23.245Z","comments":true,"path":"2017/05/10/jquery_log1/","link":"","permalink":"http://sunjx93.com/2017/05/10/jquery_log1/","excerpt":"Jquery 的一些林林总总 最近看了一本《精妙绝伦JQuery》，里面讲的比较细致，自己都快没耐心啃完了，记下来了一些自己能用到的东西，希望以后可以有所帮助","text":"Jquery 的一些林林总总 最近看了一本《精妙绝伦JQuery》，里面讲的比较细致，自己都快没耐心啃完了，记下来了一些自己能用到的东西，希望以后可以有所帮助 首先 - - 最近面试的时候问到的： 123$(document).ready 与JavaScript里onload方法的区别：$(document).ready(function()&#123;&#125;) 代表的是在DOM加载之前完成代码内加载onload 事件会在页面或图像加载完成后立即发生。 这是jQuery的一些常用方法 1234567891011121314151. .load() 预加载图片2. .ready() 事件监测DOM是否完全加载3. .unload() 在离开页面时或用户单机一个新连接是触发4. .resize() 改变浏览器大小时触发5. .scroll() 用户滚动窗口时触发6. .error() 当http请求遇到错误是触发 可以用来显示备用图片，也就是 网页上的图挂了之后，可以用别的图替代图挂了- - 表达不能23337. .bind() 绑定事件函数8. .live() 提供一个灵活的捕获事件的方式 .live(event type,event handler);9. .delegate() 三个参数：1.选择器 2.事件类型 3.响应函数 捕获鼠标事件123456789click 单击鼠标并释放dbclick 双击触发mousedown 鼠标被按下触发mouseup 鼠标松开后触发mouseenter 鼠标进入某易元素区域时触发mouseleave ..离开时触发mousemove 鼠标在区域内移动时触发mouseout 离开该区域及父元素时触发mouseover 鼠标进入某一元素及父元素时触发 捕获表单事件 123456789change() 表单值改变时触发focus() 敲TAB键触发focusin() 元素或子元素得到焦点时触发focusout() 元素或子元素失去焦点时触发blur() 文本域/文本框失去焦点时触发select() 元素内文本被选中时触发submit() 表单提交时触发reset() 重置 关于网站特效1234567show()hide()toggle() 根据当前状态显示/隐藏 切换状态slideDown() 以向下滑动展开的方式显示元素fadeIn() 元素以淡入的方式显示fadeout() 元素以淡入淡出的方式消失fadeTo() 淡入淡出至某个透明度 关于cookie（这可是他娘的重点）1234567891.如何种cookie function startCookie()&#123; var expirDate = new Date(); expirDate.setDate(expirDate.getDate+30); cookie过期时间 document.cookie = &quot;name=hideCookie;expires=&quot;+expirDate.toUTCString &#125; (可以使用jQuery的cookie插件拿到具体cookie) 注：当没有指明 cookie有效时间时，所创建的cookie有效期默认到用户关闭浏览器为止，所以被称为 “会话cookie（session cookie）”。 1234567$.cookie(&apos;cookName&apos;)$.cookie(&apos;key&apos;,&apos;value&apos;)$.cookie(&apos;key&apos;,&apos;value&apos;,&#123; expires: 7 &#125;);//意思是创建一个7天有效期的cookie$.cookie(&apos;key&apos;,&apos;value&apos;,&#123; expires: 7,path:&apos;/&apos;&#125;);//意思是创建一个7天有效期的cookie,且存储路径为/ 读取cookie：1234567$.cookie(&apos;the_cookie&apos;); // cookie存在 =&gt; &apos;the_value&apos;$.cookie(&apos;not_existing&apos;); // cookie不存在 =&gt; null5.删除cookie，通过传递null作为cookie的值即可：$.cookie(&apos;the_cookie&apos;, null); Ajax 传说中的，标志着人类互联网历史的一大步，就连名字也很后现代化的Ajax Ajax指在不需要刷新页面的情况下，允许客户端应用程序传递数据给服务器并获取数据的一组模式和技术 123456789101.$(selector).load(URL,回调函数&#123; &#125;) $(&apos;#content&apos;).load(&apos;Class5.html&apos;,function(responseText,textStatus,XMLHttpRequest)&#123; //检查不同的响应码 if(XMLHttpRequest.status == 404||XMLHttpRequest.status == 500)&#123; $(&apos;#content&apos;).html(&apos;There has been an error,please try angin later&apos;); &#125; &#125;); 关于响应码 响应码 对应解释 200 成功 301 永久跳转 302 临时跳转 400 错误请求 401 未授权 403 禁止访问 404 未找到 500 服务器错误 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071 2.载入过程的动画 在.load() 之前 $(&apos;#content&apos;).html(&apos;&lt;img...&gt;&apos;); 3.载入部分内容 $(&apos;#content&apos;).load(URL class or id or tag name ) 如： $(&apos;#content&apos;).load(&apos;class1.html.specal&apos;)------意味着该html里只有class=&quot;specal&quot; 的标签才可以被加载 4.get/post 提交表单 Get:服务器在URL中拾取键值对 Post: $.ajax(&#123; type:&apos;post&apos;, url:url, data:data, success:success, dataType:dataType &#125;); post 请求提交数据： 两种方式：标准\\快捷 标准：$.post(url,[data],[success],dataType); 快捷：$.ajax(&#123; url:url, data:data, success:success, dataType:dataType &#125;); 5.操作XML数据 a.XML是跨平台的标准 如何得到xml并解读，展示在html上 $.ajax(&#123; type:&apos;GET&apos;, url:&quot;xx.xml&quot;, dataType:&quot;XML&quot;, success:parseXML ---回调函数 &#125;);生成html function parseXML(xml)&#123; $(xml).find(&quot;Book&quot;).each(function()&#123; var author = $(this).attr(&apos;author&apos;); $(&apos;&lt;li&gt;&lt;/li&gt;&apos;).html(&apos;&lt;b&gt;Author&lt;/b&gt;:&apos;+author).appendTo(&apos;#books&apos;);; &#125;; &#125;6.操作JSon数据 json是JavaScript的表示法，它允许以键值对的形式创建自己的数据结构 a.获取json并生成html $.getJSON();或$.ajax function processJson(data)&#123; $.each(data.books,function(i,item)); &#125; 接下来要做的跟xml类似，你只需要获取item中的键值来生成html","categories":[],"tags":[{"name":"Jquery","slug":"Jquery","permalink":"http://sunjx93.com/tags/Jquery/"}]},{"title":"终于搞定了","slug":"终于搞定了","date":"2017-04-18T08:52:09.000Z","updated":"2017-05-27T08:16:30.750Z","comments":true,"path":"2017/04/18/终于搞定了/","link":"","permalink":"http://sunjx93.com/2017/04/18/终于搞定了/","excerpt":"作为小白中的小白，在升级之路上偶然看到好多大牛自己架设的博客，非常羡慕，在尝试了好久之后，终于初步搞定，微不足道的一大步，记录一下 ：）","text":"作为小白中的小白，在升级之路上偶然看到好多大牛自己架设的博客，非常羡慕，在尝试了好久之后，终于初步搞定，微不足道的一大步，记录一下 ：） 当初是看到这位的博客Giraffe’s Home然后也想自己弄一个。 来记录一下当时我整这破玩意的步骤： 首先首先你需要安装Git 和Node js Git 官网NodeJs 中文网 其次，你需要一个GItHub的账号然后，你就可以来安装hexo了 首先打开的是Git bash：对呀你得用到刚刚安的东西！ npm install -g hexo 初始化然后，执行init命令初始化hexo,命令：（你可以选择这个目录在电脑里的位置） hexo init blog blog就是你的博客根目录，所有的操作都在里面进行。以后提交啥的都要先到这个目录再提交。 hexo generate（hexo g）生成页面 如果你生成页面的时候报错，大概是hexo版本的问题，你需要先执行： npm install hexo-deployer-git –save 启动本地服务 hexo server 然后在 http://localhost4000这里就可以看到本地的博客了。 如果你想发布到网站上你需要登录GitHub账号，然后新建一个仓库（Repository），命名规则是你的GitHub用户名.github.io比如我的：Drazen08.github.io 然后：打开你本地blog文件夹，里面有一个_config.yml文件，这个需要做一些小改动： 需要注意的是！所有 ：冒号后面都要跟一个空格，要不然会报错，这里曾经困扰我好久！！！！123456title: Drazen -- 标题subtitle: the stack of it nerds -- 大概是类似座右铭之类的东西description: start from zeroauthor: JFuncnoviclanguage: zh-Hanstimezone: AsiaShanghai 需要注意的是language 和timezone ，语言和时区。 这里： 1theme: huno huno是我下载的主题，放在{目录}/theme/huno下。 最重要的是1234deploy type: git repo: git@github.comDrazen08Drazen08.github.io.git branch: master repo的地址是ssl形式的，其实好像不用这么麻烦，或许是我被墙了。。 最后执行hexo deploy 在浏览器中输入 你自己的.github.io 就可以访问了 部署步骤每次部署的步骤，可按以下三步来进行。 hexo clean hexo generate hexo deploy 一些常用命令：hexo newpostName #新建文章 hexo new pagepageName #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，ctrl + c关闭server） hexo deploy #将.deploy目录部署到GitHub hexo help # 查看帮助 hexo version #查看Hexo的版本 对了，当时好像我配置了一个ssh码关联到github上，忘记了。","categories":[],"tags":[{"name":"Hexo_Github","slug":"Hexo-Github","permalink":"http://sunjx93.com/tags/Hexo-Github/"}]}]}