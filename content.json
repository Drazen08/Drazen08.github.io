{"meta":{"title":"Drazen","subtitle":"the stack of it nerds","description":"start from zero","author":"JFuncnovic","url":"http://sunjx93.com"},"pages":[],"posts":[{"title":"prometheus 的remote write","slug":"prometheus 的remote write","date":"2019-06-10T03:13:09.000Z","updated":"2019-06-10T06:13:44.193Z","comments":true,"path":"2019/06/10/prometheus 的remote write/","link":"","permalink":"http://sunjx93.com/2019/06/10/prometheus 的remote write/","excerpt":"论如何通过java adapter获取prometheus remote write数据","text":"论如何通过java adapter获取prometheus remote write数据 1.如何实现prometheus remote write adapter java版本 prometheus 的remote write 与remote read 功能很强大，根据这两个功能，可以完全脱离对本地文件存储的依赖，并把数据存储变为可自定义的，现在来调研一下这个功能。 prometheus 官方提供各种remote write 的适配器，但唯独没有java语言的。prometheus 官方remote write 版本 所以现在想解析prometheus 指标数据。 1.remote write根据prometheus 的配置文件可以得知，remote_write 后面跟一个url路径，prometheus 会把每次刮取到的数据推到这个url上，于是我实现了一个简单的http接口： 1234@PostMapping(&quot;/xx&quot;)public void getmsg(@RequestBody String msg)&#123; xxx&#125; 但是发现报了一堆提示无法解析的错误，百度了一下发现是prometheus 的remote write格式比较特殊。于是： 翻到prometheus github 源码，找到remote write 的文件格式：https://github.com/prometheus/prometheus/blob/master/prompb/remote.proto，并下载下来 同时需要下载同路径文件type.proto,这两个文件互为依赖，最后把其他的依赖删掉 remote.proto的头部 12345syntax = &quot;proto3&quot;;package prometheus;option go_package = &quot;prompb&quot;;import &quot;types.proto&quot;;import &quot;gogoproto/gogo.proto&quot;; // 删掉 types.proto的头部 1234syntax = &quot;proto3&quot;;package prometheus;option go_package = &quot;prompb&quot;;import &quot;gogoproto/gogo.proto&quot;; // 删掉 至于为什么删掉，因为该依赖对于java来说没什么用处： 相关issue 1.1 引入依赖 a.引入protobuf 1234567891011121314151617181920212223242526272829303132333435&lt;properties&gt; &lt;grpc.version&gt;1.7.0&lt;/grpc.version&gt; &lt;protobuf.version&gt;3.4.0&lt;/protobuf.version&gt; &lt;snappy.version&gt;1.1.4&lt;/snappy.version&gt;&lt;/properties&gt;&lt;!--protobuf &amp; java --&gt;&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-netty&lt;/artifactId&gt; &lt;version&gt;$&#123;grpc.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-protobuf&lt;/artifactId&gt; &lt;version&gt;$&#123;grpc.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-stub&lt;/artifactId&gt; &lt;version&gt;$&#123;grpc.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt; &lt;artifactId&gt;protobuf-java&lt;/artifactId&gt; &lt;version&gt;$&#123;protobuf.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.xerial.snappy&lt;/groupId&gt; &lt;artifactId&gt;snappy-java&lt;/artifactId&gt; &lt;version&gt;$&#123;snappy.version&#125;&lt;/version&gt;&lt;/dependency&gt; 1.2 引入maven插件，用于把.proto 文件转化为.java 文件1234567891011121314151617181920212223242526272829303132333435&lt;build&gt; &lt;extensions&gt; &lt;extension&gt; &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt; &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.0.Final&lt;/version&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.5.0&lt;/version&gt; &lt;configuration&gt; &lt;protocArtifact&gt;com.google.protobuf:protoc:$&#123;protobuf.version&#125;:exe:$&#123;os.detected.classifier&#125; &lt;/protocArtifact&gt; &lt;pluginId&gt;grpc-java&lt;/pluginId&gt; &lt;pluginArtifact&gt;io.grpc:protoc-gen-grpc-java:$&#123;grpc.version&#125;:exe:$&#123;os.detected.classifier&#125; &lt;/pluginArtifact&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;compile-custom&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 1.3 重新编译项目，生成.java 文件 注意： 新生成的文件路径参照.proto文件内package的具体值。 文件不是源码形式，而是编译后的.class文件，在target目录下 1.4 重写rest api123456789101112@PostMapping(value = &quot;write&quot;)public void metrics(@RequestBody byte[] data) throws Exception &#123; byte[] compressed; Remote.WriteRequest writeRequest=null; try &#123; compressed = Snappy.uncompress(data); writeRequest = Remote.WriteRequest.parseFrom(compressed); log.debug(&quot;info from Prometheus:&#123;&#125;&quot;, writeRequest); &#125; catch (IOException e) &#123; log.error(&quot;receive msg from Prometheus error&quot;, e); &#125;&#125; 1.5 最后至此，得出的writerequest 就是prometheus remote write 经处理后的数据。 2. prometheus 向influxdb存储数据 prometheus 大多与时序数据库一起结合使用，比较好的时序数据库有influxdb,OpenTSDB,Druid等等。这里使用influxdb进行调研 influxdb 关于prometheus的支持 可以看到：influxdb 1.7+ 天然支持prometheus的remote read，以及remote write功能，也就是说，上文的java adapter是没有什么卵用的。。 不过至少了解了prometheus api的通信格式，也可以在以后进行脱离influxdb 的定制自开发。","categories":[],"tags":[{"name":"prometheus","slug":"prometheus","permalink":"http://sunjx93.com/tags/prometheus/"}]},{"title":"k8s configmap 的使用","slug":"configmap的使用&prometheus","date":"2019-06-06T02:34:09.000Z","updated":"2019-06-06T03:08:09.659Z","comments":true,"path":"2019/06/06/configmap的使用&prometheus/","link":"","permalink":"http://sunjx93.com/2019/06/06/configmap的使用&prometheus/","excerpt":"一个关于k8s configmap的小总结~~~","text":"一个关于k8s configmap的小总结~~~ configmap是k8s的一个重要的组件，顾名思义，configmap是一个关于配置的集合组件，事实上，有点像基于kv对的形式进行存储和使用的。 1、一个configmap的例子1234567891011apiVersion: v1kind: ConfigMapmetadata: name: prometheus-config namespace: kube-system labels: kubernetes.io/cluster-service: &quot;true&quot; addonmanager.kubernetes.io/mode: EnsureExistsdata: prometheus.yml: | ....... 以上是prometheus的configmap配置文件，与prometheus.yml 对应的就是该yml文件内的所有内容，当这个configmap创建之后，configmap会生成一个虚拟的文件夹，由别的container来挂载configmap中prometheus.yml这个配置文件。 2、configmap的创建configmap创建拥有多种形式，可以通过命令行，文件、文件夹、或者直接通过k8s client的api进行创建。 kubectl create -f configmap-demo.yml:这种方式会把上面的yml文件创建为configmap kubectl create configmap &lt;name&gt; --from-file=prometheus.yml: 这种方式会把prometheus.yml作为configmap的data进行创建 kubectl create configmap my -config --from-file=/path/to/dir:当采用这种方式时，k8s会寻找这个文件夹下面所有符合规范的文件，把所有文件作为configmap的data来创建configmap 还有一种根据api来修改configmap的方法，最后说 3.configmap的使用configmap有三种使用的方式: 环境变量 使用configmap将条目暴露为文件 挂载configmap的特定文件 3.1 环境变量形式 valueFrom12345678910111213apiVers ion: vlkind: Podmetadata: name: xxspec: containers: - image: xx env: - name: ENV_NAME valueFrom: configMapKeyRef: name: &lt;configmap name&gt; key: &lt;configmap data key&gt; 3.2 使用configmap将条目暴露为文件 configmap 会把符合条件的配置生成为虚拟目录，生成到pod指定的目录下，如下文就是在/etc/config/xx目录下 123456789101112131415apiVers ion: vlkind: Podmetadata: name: xxspec: containers: - image: xx volumeMounts: - name: config mountPath: /etc/config/xx readOnly:true volumes: - name: config configMap: name: &lt;configmap name&gt; 3.3 使用configmap的特定文件1234567891011apiVers ion: vlkind: Podmetadata: name: xxspec: containers: - image: some/image volumeMounts: - name: myvolume mountPath: /etc/someconfig.conf # 要挂载的目标文件 subPath: myconfig.conf # configmap 内的文件名 4.configmap 与prometheus 结合贴一个k8s 官方提供的prometheus 配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107apiVersion: apps/v1kind: StatefulSetmetadata: name: prometheus namespace: kube-system labels: k8s-app: prometheus kubernetes.io/cluster-service: &quot;true&quot; addonmanager.kubernetes.io/mode: Reconcile version: v2.8.1spec: serviceName: &quot;prometheus&quot; replicas: 1 podManagementPolicy: &quot;Parallel&quot; updateStrategy: type: &quot;RollingUpdate&quot; selector: matchLabels: k8s-app: prometheus template: metadata: labels: k8s-app: prometheus annotations: scheduler.alpha.kubernetes.io/critical-pod: &apos;&apos; spec: priorityClassName: system-cluster-critical serviceAccountName: prometheus initContainers: - name: &quot;init-chown-data&quot; image: &quot;busybox:latest&quot; imagePullPolicy: &quot;IfNotPresent&quot; command: [&quot;chown&quot;, &quot;-R&quot;, &quot;65534:65534&quot;, &quot;/data&quot;] volumeMounts: - name: prometheus-data mountPath: /data subPath: &quot;&quot; containers: - name: prometheus-server-configmap-reload image: &quot;jimmidyson/configmap-reload:v0.1&quot; imagePullPolicy: &quot;IfNotPresent&quot; args: - --volume-dir=/etc/config - --webhook-url=http://localhost:9090/-/reload volumeMounts: - name: config-volume mountPath: /etc/config readOnly: true resources: limits: cpu: 10m memory: 10Mi requests: cpu: 10m memory: 10Mi - name: prometheus-server image: &quot;prom/prometheus:v2.8.1&quot; imagePullPolicy: &quot;IfNotPresent&quot; args: - --config.file=/etc/config/prometheus.yml - --storage.tsdb.path=/data - --web.console.libraries=/etc/prometheus/console_libraries - --web.console.templates=/etc/prometheus/consoles - --web.enable-lifecycle ports: - containerPort: 9090 readinessProbe: httpGet: path: /-/ready port: 9090 initialDelaySeconds: 30 timeoutSeconds: 30 livenessProbe: httpGet: path: /-/healthy port: 9090 initialDelaySeconds: 30 timeoutSeconds: 30 # based on 10 running nodes with 30 pods each resources: limits: cpu: 200m memory: 1000Mi requests: cpu: 200m memory: 1000Mi volumeMounts: - name: config-volume mountPath: /etc/config - name: prometheus-data mountPath: /data subPath: &quot;&quot; terminationGracePeriodSeconds: 300 volumes: - name: config-volume configMap: name: prometheus-config volumeClaimTemplates: - metadata: name: prometheus-data spec: storageClassName: slow accessModes: - ReadWriteOnce resources: requests: storage: &quot;16Gi&quot; 在上面的配置中，k8s官方利用了prometheus的热加载特性，内置了一个jimmidyson/configmap-reload:v0.1的container，它的作用就是在configmap发生变化时通过配置好的url来通知prometheus进行热加载。所以下文我们需要讲讲怎么通过k8s client 来进行configmap的更新。 5.k8s client java版本 k8s 官方提供了很多不同语言、不同种类的k8s客户端k8s 官网client列表 在这里选择的是fabric8io,一个对于Java友好的开源微服务管理平台。 引入依赖: 由于节点的k8s版本是1.13+,所以要使用最新版本 12345&lt;dependency&gt; &lt;groupId&gt;io.fabric8&lt;/groupId&gt;x` &lt;artifactId&gt;kubernetes-client&lt;/artifactId&gt; &lt;version&gt;4.2.2&lt;/version&gt;&lt;/dependency&gt; 建立与k8s服务端的连接： 1234567891011Config config = new ConfigBuilder().withMasterUrl(MASTER_URL) .withTrustCerts(true) .withCaCertFile(&quot;/ca.crt&quot;) // 在这里的参数都是文件路径 .withClientKeyFile(&quot;/kubecfg.key&quot;) // 在这里的参数都是文件路径 .withClientCertFile(&quot;/kubecfg.crt&quot;) // 在这里的参数都是文件路径 .removeFromTlsVersions(TlsVersion.TLS_1_0) .removeFromTlsVersions(TlsVersion.TLS_1_1) .removeFromTlsVersions(TlsVersion.TLS_1_2) .withRequestTimeout(REQUEST_TIMEOUT) .withConnectionTimeout(CONNECTION_TIMEOUT) .build(); 在这里需要强调，如果你的k8s集群需要证书认证，则在创建config实例时需要生成双向认证证书，并把证书放入指定目录，如果不需要证书的话，则可以去掉大部分配置。 如何生成双向认证的证书： 123456# 生成client crtgrep &apos;client-certificate-data&apos; ~/.kube/config | head -n 1 | awk &apos;&#123;print $2&#125;&apos; | base64 -d &gt;&gt; kubecfg.crt# 生成client keygrep &apos;client-key-data&apos; ~/.kube/config | head -n 1 | awk &apos;&#123;print $2&#125;&apos; | base64 -d &gt;&gt; kubecfg.key 执行上述两条命令后，把生成的kubecfg.crt 与 kubecfg.key 保存到指定目录下即可。 如何获取configmap的详细数据 12345KubernetesClient client = new DefaultKubernetesClient(config);Resource&lt;ConfigMap, DoneableConfigMap&gt; configMapResource.client.configMaps().inNamespace(namespace). withName(name); ConfigMap configMap = configMapResource.get(); Map&lt;String, String&gt; data = configMap.getData(); 在这里data就是configmap的data属性，内部就是文件名-文件内容的kv对，所有对configmap的修改都是在configmapresource内进行的。","categories":[],"tags":[{"name":"k8s","slug":"k8s","permalink":"http://sunjx93.com/tags/k8s/"}]},{"title":"etcd 集群的部署","slug":"etcd-install","date":"2019-06-05T07:34:09.000Z","updated":"2019-06-06T02:55:11.245Z","comments":true,"path":"2019/06/05/etcd-install/","link":"","permalink":"http://sunjx93.com/2019/06/05/etcd-install/","excerpt":"一个关于etcd集群部署的总结","text":"一个关于etcd集群部署的总结 环境： centos7+node节点机器需要互相ping通 服务器列表：| 公网ip | 内网ip | 角色 || ————- | ————– | —— || 39.96.46.94 | 172.17.34.80 | master || 39.96.11.112 | 172.17.34.79 | node || 39.105.65.204 | 172.17.198.174 | node | 一、部署etcd 集群1.cfssl 安装 自定一个文件路径，在该路径下执行以下命令 12345678910111213141516wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64chmod +x cfssl_linux-amd64sudo mv cfssl_linux-amd64 /usr/local/bin/cfsslwget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64chmod +x cfssljson_linux-amd64sudo mv cfssljson_linux-amd64 /usr/local/bin/cfssljsonwget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64chmod +x cfssl-certinfo_linux-amd64sudo mv cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfocfssl gencert -initca ca-csr.json | cfssljson -bare caexport PATH=/bin:/usr/bin:$PATHcfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=etcd etcd-csr.json | cfssljson -bare etcd 2.创建ssl证书1234567891011121314151617mkdir -p /opt/cfssl/etcdSSLcd /opt/cfssl/etcdSSLwget https://github.com/Drazen08/myConfig/blob/master/kubernetes/opt/cfssl/etcdSSL/ca-config.jsonwget https://github.com/Drazen08/myConfig/blob/master/kubernetes/opt/cfssl/etcdSSL/ca-csr.jsoncfssl gencert -initca ca-csr.json | cfssljson -bare cawget https://github.com/Drazen08/myConfig/blob/master/kubernetes/opt/cfssl/etcdSSL/etcd-csr.jsoncfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=etcd etcd-csr.json | cfssljson -bare etcdmkdir -p /etc/etcd/etcdSSLcp /opt/cfssl/etcdSSL/* /etc/etcd/etcdSSL 下载下来的json 文件可以自行配置 3.安装etcd3.1静态配置ip为80服务器etcd部署 3.1.1 cfssl 工具的安装 ，用于创建各类证书。安装方式可自行百度。3.1.2 创建目录 /opt /opt/cfssl/etcdSSL3.1.3 创建 CA 配置文件（ca-config.json）{ &quot;signing&quot;: { &quot;default&quot;: { &quot;expiry&quot;: &quot;876000h&quot; }, &quot;profiles&quot;: { &quot;etcd&quot;: { &quot;usages&quot;: [ &quot;signing&quot;, &quot;key encipherment&quot;, &quot;server auth&quot;, &quot;client auth&quot; ], &quot;expiry&quot;: &quot;876000h&quot; } } } } 12345&quot;字段说明&quot;&quot;ca-config.json&quot;：可以定义多个 profiles，分别指定不同的过期时间、使用场景等参数；后续在签名证书时使用某个 profile；&quot;signing&quot;：表示该证书可用于签名其它证书；生成的 ca.pem 证书中 CA=TRUE；&quot;server auth&quot;：表示client可以用该 CA 对server提供的证书进行验证；&quot;client auth&quot;：表示server可以用该CA对client提供的证书进行验证； 3.1.4 创建 CA 证书签名请求（ca-csr.json）123456789101112131415&#123; &quot;CN&quot;: &quot;etcd&quot;, &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;shenzhen&quot;, &quot;L&quot;: &quot;shenzhen&quot;, &quot;O&quot;: &quot;etcd&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125; 1234&quot;CN&quot;：Common Name，etcd 从证书中提取该字段作为请求的用户名 (User Name)；浏览器使用该字段验证网站是否合法；&quot;O&quot;：Organization，etcd 从证书中提取该字段作为请求用户所属的组 (Group)；这两个参数在后面的kubernetes启用RBAC模式中很重要，因为需要设置kubelet、admin等角色权限，那么在配置证书的时候就必须配置对了，具体后面在部署kubernetes的时候会进行讲解。&quot;在etcd这两个参数没太大的重要意义，跟着配置就好。&quot; 3.1.5 生成 CA 证书和私钥12cfssl gencert -initca ca-csr.json | cfssljson -bare ca说明：生成 &quot;ca-csr.json ca-key.pem ca.pem&quot; 三个文件 3.1.6 创建 etcd证书签名请求（etcd-csr.json）12345678910111213141516171819202122&#123; &quot;CN&quot;: &quot;etcd&quot;, &quot;hosts&quot;: [ &quot;127.0.0.1&quot;, &quot;172.17.34.80&quot;, &quot;172.17.34.79&quot;, &quot;172.17.198.174&quot; ], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;shenzhen&quot;, &quot;L&quot;: &quot;shenzhen&quot;, &quot;O&quot;: &quot;etcd&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125; 3.1.7 生成 etcd证书和私钥123cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=etcd etcd-csr.json | cfssljson -bare etcd生成 &quot;etcd-csr.json etcd-key.pem etcd.pem&quot; 三个文件。 3.1.8 确认生成证书列表 并 创建 /etc/etcd/etcdSSL 目录3.1.9 将所有证书文件拷贝至 /etc/etcd/etcdSSL 目录 cp /opt/cfssl/etcdSSL/* /etc/etcd/etcdSSL 3.1.10 安装 etcd服务 yum install -y etcd 3.1.11 配置 etcd 的 service文件（/usr/lib/systemd/system） vim /usr/lib/systemd/system/etcd.service 123456789101112131415161718192021222324252627282930313233[Unit]Description=Etcd ServerAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]Type=notifyWorkingDirectory=/var/lib/etcd/EnvironmentFile=-/etc/etcd/etcd.conf# set GOMAXPROCS to number of processorsExecStart=/usr/bin/etcd \\ --name $&#123;ETCD_NAME&#125; \\ --cert-file=/etc/etcd/etcdSSL/etcd.pem \\ --key-file=/etc/etcd/etcdSSL/etcd-key.pem \\ --peer-cert-file=/etc/etcd/etcdSSL/etcd.pem \\ --peer-key-file=/etc/etcd/etcdSSL/etcd-key.pem \\ --trusted-ca-file=/etc/etcd/etcdSSL/ca.pem \\ --peer-trusted-ca-file=/etc/etcd/etcdSSL/ca.pem \\ --initial-advertise-peer-urls $&#123;ETCD_INITIAL_ADVERTISE_PEER_URLS&#125; \\ --listen-peer-urls $&#123;ETCD_LISTEN_PEER_URLS&#125; \\ --listen-client-urls $&#123;ETCD_LISTEN_CLIENT_URLS&#125;,http://127.0.0.1:2379 \\ --advertise-client-urls $&#123;ETCD_ADVERTISE_CLIENT_URLS&#125; \\ --initial-cluster-token $&#123;ETCD_INITIAL_CLUSTER_TOKEN&#125; \\ --initial-cluster infra1=https://172.17.34.80:2380,https://172.17.34.79:2380,https://172.17.198.174:2380 \\ --initial-cluster-state new \\ --data-dir=$&#123;ETCD_DATA_DIR&#125;Restart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.target 1234567891011121314151617181920212223242526272829参数说明：1、指定 etcd 的工作目录为 /var/lib/etcd，数据目录为 /var/lib/etcd，需在启动服务前创建这两个目录；在配置中的命令是这条：WorkingDirectory=/var/lib/etcd/2、为了保证通信安全，需要指定 etcd 的公私钥(cert-file和key-file)、Peers 通信的公私钥和 CA 证书(peer-cert-file、peer-key-file、peer-trusted-ca-file)、客户端的CA证书（trusted-ca-file）；在配置中添加etcd证书的命令是以下： --cert-file=/etc/etcd/etcdSSL/etcd.pem \\ --key-file=/etc/etcd/etcdSSL/etcd-key.pem \\ --peer-cert-file=/etc/etcd/etcdSSL/etcd.pem \\ --peer-key-file=/etc/etcd/etcdSSL/etcd-key.pem \\ --trusted-ca-file=/etc/etcd/etcdSSL/ca.pem \\ --peer-trusted-ca-file=/etc/etcd/etcdSSL/ca.pem \\3、配置etcd的endpoint：--initial-cluster infra1=https:// 172.17.34.80:2380,infra2=https:// 172.17.34.79:2380,infra3=https:// 172.17.198.174:2380 \\4、配置etcd的监听服务集群： --initial-advertise-peer-urls $&#123;ETCD_INITIAL_ADVERTISE_PEER_URLS&#125; \\ --listen-peer-urls $&#123;ETCD_LISTEN_PEER_URLS&#125; \\ --listen-client-urls $&#123;ETCD_LISTEN_CLIENT_URLS&#125;,http://127.0.0.1:2379 \\ --advertise-client-urls $&#123;ETCD_ADVERTISE_CLIENT_URLS&#125; \\5、配置etcd创建的集群为新集群，则定义集群状态为new --initial-cluster-state 值为 new6、定义etcd节点的名称，该名称等下从配置文件中获取： --name $&#123;ETCD_NAME&#125; \\ 其中配置文件：EnvironmentFile=-/etc/etcd/etcd.conf 3.1.12 编写 etcd的配置文件（/etc/etcd/etcd.conf）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#[Member]#ETCD_CORS=&quot;&quot;ETCD_DATA_DIR=&quot;/var/lib/etcd&quot;#ETCD_WAL_DIR=&quot;&quot;ETCD_LISTEN_PEER_URLS=&quot;https://172.17.34.80:2380&quot;ETCD_LISTEN_CLIENT_URLS=&quot;https://172.17.34.80:2379&quot;#ETCD_MAX_SNAPSHOTS=&quot;5&quot;#ETCD_MAX_WALS=&quot;5&quot;ETCD_NAME=&quot;infra1&quot;#ETCD_SNAPSHOT_COUNT=&quot;100000&quot;#ETCD_HEARTBEAT_INTERVAL=&quot;100&quot;#ETCD_ELECTION_TIMEOUT=&quot;1000&quot;#ETCD_QUOTA_BACKEND_BYTES=&quot;0&quot;#ETCD_MAX_REQUEST_BYTES=&quot;1572864&quot;#ETCD_GRPC_KEEPALIVE_MIN_TIME=&quot;5s&quot;#ETCD_GRPC_KEEPALIVE_INTERVAL=&quot;2h0m0s&quot;#ETCD_GRPC_KEEPALIVE_TIMEOUT=&quot;20s&quot;##[Clustering]ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://172.17.34.80:2380&quot;ETCD_ADVERTISE_CLIENT_URLS=&quot;https://172.17.34.80:2379&quot;#ETCD_DISCOVERY=&quot;&quot;#ETCD_DISCOVERY_FALLBACK=&quot;proxy&quot;#ETCD_DISCOVERY_PROXY=&quot;&quot;#ETCD_DISCOVERY_SRV=&quot;&quot;#ETCD_INITIAL_CLUSTER=&quot;default=http://localhost:2380&quot;ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;#ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;#ETCD_STRICT_RECONFIG_CHECK=&quot;true&quot;#ETCD_ENABLE_V2=&quot;true&quot;##[Proxy]#ETCD_PROXY=&quot;off&quot;#ETCD_PROXY_FAILURE_WAIT=&quot;5000&quot;#ETCD_PROXY_REFRESH_INTERVAL=&quot;30000&quot;#ETCD_PROXY_DIAL_TIMEOUT=&quot;1000&quot;#ETCD_PROXY_WRITE_TIMEOUT=&quot;5000&quot;#ETCD_PROXY_READ_TIMEOUT=&quot;0&quot;##[Security]#ETCD_CERT_FILE=&quot;&quot;#ETCD_KEY_FILE=&quot;&quot;#ETCD_CLIENT_CERT_AUTH=&quot;false&quot;#ETCD_TRUSTED_CA_FILE=&quot;&quot;#ETCD_AUTO_TLS=&quot;false&quot;#ETCD_PEER_CERT_FILE=&quot;&quot;#ETCD_PEER_KEY_FILE=&quot;&quot;#ETCD_PEER_CLIENT_CERT_AUTH=&quot;false&quot;#ETCD_PEER_TRUSTED_CA_FILE=&quot;&quot;#ETCD_PEER_AUTO_TLS=&quot;false&quot;##[Logging]#ETCD_DEBUG=&quot;false&quot;#ETCD_LOG_PACKAGE_LEVELS=&quot;&quot;#ETCD_LOG_OUTPUT=&quot;default&quot;##[Unsafe]#ETCD_FORCE_NEW_CLUSTER=&quot;false&quot;##[Version]#ETCD_VERSION=&quot;false&quot;#ETCD_AUTO_COMPACTION_RETENTION=&quot;0&quot;##[Profiling]#ETCD_ENABLE_PPROF=&quot;false&quot;#ETCD_METRICS=&quot;basic&quot;##[Auth]#ETCD_AUTH_TOKEN=&quot;simple&quot; 这是172.17.34.80节点的配置，如果配置其他etcd节点只要将上面的IP地址改成相应节点的IP地址即可。 3.1.13 启动 etcd 服务1234systemctl daemon-reloadsystemctl enable etcdsystemctl start etcdsystemctl status etcd 3.2 ip 为 79 和 174 服务器的etcd部署3.2.1 证书文件拷贝 将 80服务器上/etc/etcd/etcdSSL 目录下的证书文件分别拷贝到 79 和 174 上的同样目录下/etc/etcd/etcdSSL/。 3.2.2 分别安装etcd同 1.1.2 3.2.3 分别配置etcd的service文件同 1.1.11 3.2.4 分别编写etcd的配置文件 etcd.conf同 1.1.12 3.2.5 分别启动etcd服务同 1.1.13 3.3. 检查etcd健康状况12345etcdctl \\ --ca-file=/etc/etcd/etcdSSL/ca.pem \\ --cert-file=/etc/etcd/etcdSSL/etcd.pem \\ --key-file=/etc/etcd/etcdSSL/etcd-key.pem \\ cluster-health 返回如下则为安装成功： 1234member 2dbd9a0c7ed8083a is healthy: got healthy result from https://172.17.34.79:2379member 919be24b29e0636b is healthy: got healthy result from https://172.17.34.80:2379member d767afc27e01c0a3 is healthy: got healthy result from https://172.17.198.174:2379cluster is healthy 动态配置 （服务发现） etcd 服务自发现的原理是通过一个现有的etcd 集群来启动一个新的etcd 集群 1.etcd 自发现 可以借助etcd官方提供的公网etcd集群进行自发现 步骤 执行curl https://discovery.etcd.io/new?size=? 命令，其中? 代表节点个数 第一步的应答值保存下来，是一个etcd官网提供的url，该url用来以后写入配置文件，如：https://discovery.etcd.io/XXXX 我把模板文件放在远程仓库，所以可以直接执行命令：（如果你不需要证书，则注释掉etcd.conf文件中#[Security]项的子项配置，且把所有url变更为http类型）1234cd /etc/etcdwget https://github.com/Drazen08/myConfig/blob/master/etcd/dynamic/etc/etcd/etcd.confcd /usr/lib/systemd/systemwget https://github.com/Drazen08/myConfig/blob/master/etcd/dynamic/usr/lib/systemd/system/etcd.service 执行vim /etc/etcd/etcd.conf, 把文件中ip换成本节点的ip，以上操作所有节点通用 执行命令： 1234systemctl daemon-reloadsystemctl enable etcdsystemctl start etcdsystemctl status etcd 注意，上述步骤是对etcd.conf进行操作，我们也可以放弃conf,直接用命令进行服务发现：123456789101112etcd --name &lt;etcd node name&gt; --data-dir &lt;your data dir&gt; \\--initial-advertise-peer-urls &lt;node-ip:2379&gt; \\--listen-peer-urls &lt;node-ip:2380&gt;\\--listen-client-urls &lt;node-ip:2379&gt;,http://127.0.0.1:2379 \\--advertise-client-urls &lt;node-ip:2379&gt; \\--discovery https://discovery.etcd.io/XXXX--cert-file=/etc/etcd/etcdSSL/etcd.pem \\--key-file=/etc/etcd/etcdSSL/etcd-key.pem \\--peer-cert-file=/etc/etcd/etcdSSL/etcd.pem \\--peer-key-file=/etc/etcd/etcdSSL/etcd-key.pem \\--trusted-ca-file=/etc/etcd/etcdSSL/ca.pem \\--peer-trusted-ca-file=/etc/etcd/etcdSSL/ca.pem \\ 如果你没有证书，则去掉--discovery 项之后的配置，该命令每个节点执行一次 当操作完成后，执行命令进行检查1etcdctl --ca-file=/etc/etcd/etcdSSL/ca.pem --cert-file=/etc/etcd/etcdSSL/etcd.pem --key-file=/etc/etcd/etcdSSL/etcd-key.pem --endpoints=https://172.17.34.80:2379,https://172.17.34.79:2379,https://172.17.198.174:2379 cluster-health 如果你在后期想增加节点，则可以执行： 1etcdctl --ca-file=/etc/etcd/etcdSSL/ca.pem --cert-file=/etc/etcd/etcdSSL/etcd.pem --key-file=/etc/etcd/etcdSSL/etcd-key.pem --endpoints=https://172.17.34.80:2379,https://172.17.34.79:2379,https://172.17.198.174:2379 member add &lt;node name&gt; &lt;node url&gt; 2.DNS 自发现 原理是利用DNS的SRV记录不断轮训查询实现的。DNS SRV是DNS数据库中支持的一种资源记录的类型，它记录了哪台计算机提供了哪个服务这么一个简单信息。 可以采用dnsmasq作为dns服务器，进行dns自发现","categories":[],"tags":[{"name":"etcd","slug":"etcd","permalink":"http://sunjx93.com/tags/etcd/"}]},{"title":"prometheus 划水","slug":"prometheus","date":"2019-05-10T03:13:09.000Z","updated":"2019-06-05T07:39:42.511Z","comments":true,"path":"2019/05/10/prometheus/","link":"","permalink":"http://sunjx93.com/2019/05/10/prometheus/","excerpt":"入职了新公司，需要我去了解prometheus，记录一下prometheus 的心得，不定期更新","text":"入职了新公司，需要我去了解prometheus，记录一下prometheus 的心得，不定期更新 先挂官网 https://prometheus.io 比较重要的点： 创建prometheus 服务及配置 remote read &amp; remote write remote read (write) 思考 以及一些小坑 如何获取remote write 消息，并把它转成可以使用的数据 remote write 持久化指标数据至influx db PushGateway &amp; push clint (这里贴java client) exporter 相关：snmp,node,StatsD等… alertmanager 配置 k8s 部署prometheus 集群 1. 创建prometheus服务 网上有现成的，不想写… 2. remote_read &amp; remote_write prometheus 提供了两个功能，用于监控指标的数据拉取以及存储 a.remote read (write) 思考 注意： remote_read 必须置于顶层，且read_recent 应当为true remote_read 可以配置prometheus server,也可以配置 influxdb （1.7+） remote_write 可以配置 自己的prometheus remote adapter,也可以配置 1.7版本以上的influxdb 如何配置 remote_read12345remote_read: - url: http://host:9090/api/v1/read read_recent: trueremote_write: - url: http://host:port/xx 思考 ： 根据remote_read 进行读写分离，即A prometheus服务进行读，不负责写，B prometheus 负责写，不负责读。且读prometheus 会产生本地数据，可以手动设置清除频率高一点 b.如何获取remote write 消息，并把它转成可以使用的数据 首先,prometheus自身的remote_write 数据格式其实并不通用————application/x-protobuf，而且官方并没有给出基于java的适配器(adapter)————大多数是用go语言写的，所以假如是想二次开发什么的就多了一些成本… 首先你可以滚去学go语言… 或者自己实现一套java版本的adapter ———— 记获取prometheus remote_write 踩坑记 influxdb 记一个influxdb 坑 pushgate way push gate way 推送到固定地址 ，最后由prometheus 收集该操作需要有自己的PushGateWay 节点,PushGateway 相当于一个prometheus 的缓存buffer java client1234567891011121314151617CollectorRegistry registry = new CollectorRegistry();Gauge duration = Gauge.build() .name(&quot;my_batch_job_duration_seconds&quot;).help(&quot;Duration of my batch job in seconds.&quot;).register(registry);Gauge.Timer durationTimer = duration.startTimer();try &#123; // Your code here. // This is only added to the registry after success, // so that a previous success in the Pushgateway isn&apos;t overwritten on failure. Gauge lastSuccess = Gauge.build() .name(&quot;my_batch_job_last_success&quot;).help(&quot;Last time my batch job succeeded, in unixtime.&quot;).register(registry); lastSuccess.setToCurrentTime();&#125; finally &#123; durationTimer.setDuration(); PushGateway pg = new PushGateway(&quot;39.96.11.112:9091&quot;); pg.pushAdd(registry, &quot;my_batch_job&quot;);&#125; SNMP Exporterprometheus 官方 snmp_exporter 1.如何使用 找到官方github地址 clone到服务器本地 下载snmp exporter 官方提供的release包,如tar.gz 格式 解压下载好的包放到已经clone好的本地目录中 执行docker build命令 成功创建镜像 对带监控机器开启snmp协议 2.snmphttp://host:9116/snmp?target=1.2.3.4&amp;module=if_mib 疑似修改配置文件 Alert Manager Alertmanager can reload its configuration at runtime. If the new configuration is not well-formed, the changes will not be applied and an error is logged. alertmanager 在运行时可以加载配置 ，若新的配置不正确，则仍运行上一个版本的配置，且报告错误 保存历史指标数据 --storage.tsdb.path, Defaults to data/ --storage.tsdb.retention.time ,保存几天的历史数据， Defaults to 15d --storage.tsdb.retention.size max 存量，实验性质的配置 --storage.tsdb.retention","categories":[],"tags":[{"name":"prometheus","slug":"prometheus","permalink":"http://sunjx93.com/tags/prometheus/"}]},{"title":"docker 非专业记录","slug":"docker","date":"2019-04-26T15:08:09.000Z","updated":"2019-06-05T07:40:28.929Z","comments":true,"path":"2019/04/26/docker/","link":"","permalink":"http://sunjx93.com/2019/04/26/docker/","excerpt":"怎么硕呢，离职了，感谢曾经一起奋斗过的同事，至少跟你们一起周六上班的时光很美。","text":"怎么硕呢，离职了，感谢曾经一起奋斗过的同事，至少跟你们一起周六上班的时光很美。 为啥要用docker docker可以偷懒 免去部署麻烦 不用到处去某官网忍受那几k的墙内网速去下载安装包 一套镜像，终身受益 独立、纯洁、沙箱的运行环境 其实主要还是方便，毕竟偷懒是推动世界的源动力 用docker我干过什么 似乎这标题挺邪恶的… 部署运行代码用它 创建数据库、数据库集群用它 好像这东西跟微服务有点关系… docker的主要命令 命令 解释 备注 yum install docker 安装docker service docker start 启动docker systemctl enable docker 开机启动docker docker version 查看docker版本 docker search tutorial 搜索可用docker镜像 好像需要翻墙 docker images 获取宿主机的docker镜像 docker image rm 删除本地镜像 docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; …] docker image ls -f dangling=true 清除虚悬镜像的命令 由于版本更迭造成低版本镜像有为&lt;none&gt;的情况 docker pull 从docker仓库拉取镜像 docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] docker ps 获取docker容器列表 docker commit 698 learn/ping 保存对容器的修改 698 代表容器前3位id，后面是容器名称 docker inspect xx 查看某一容器详细信息 xx 代表容器名称 docker system df 查看镜像、容器、数据卷所占用的空间。 docker run 运行容器 docker exec -it xx /path 进入容器内部 xx代表镜像名称 /path 代表容器路径 docker logs -f –tail 500 xx 查看某容器前500行日志 xx 代表容器名称 docker cp /etc/localtime xx:/etc/ 修改docker 容器时间与linux宿主时间一致 xx代表具体的容器id docker run -p 8086:8086 -it cloud_websocket /bin/bash 创建docker容器 8086:8086 代表容器内部端口:对外端口 此操作需要Dockerfile docker run –name=grid-auto-dispatch-task -p 9065:9065 -idt -v /servers/docker-jar/grid-auto-dispatch-task:/usr/Downloads bolingcavalry/springbootrun:0.0.2 根据image创建并运行容器 -p：宿主机端口与容器端口映射 -v:将宿主机文件映射到容器中，做共享文件夹 –name：容器名称 sudo yum remove docker docker-common docker-selinux docker-engine 卸载docker组件 docker run -it：这是两个参数，一个是 -i：交互式操作，一个是 -t 终端。我们这里打算进入 bash 执行一些命令并查看返回结果，因此我们需要交互式终端。 –rm：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 –rm 可以避免浪费空间。 bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 bash。 DockerFile 定制镜像 Dockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 通过 docker build 根据Dockerfile 创建容器 Dockerfile 指令详解 指令 作用 备注 FROM 功能为指定基础镜像，并且必须是第一条指令。 如果不以任何镜像为基础，那么写法为：FROM scratch RUN 功能为运行指定的命令 RUN ... CMD 功能为容器启动时要运行的命令 RUN是构件容器时就运行的命令以及提交运行结果,CMD是容器启动时执行的命令，在构件时并不运行，构件时紧紧指定了这个命令到底是个什么样子 COPY 一个复制命令，把文件复制到景象中 ADD 一个复制命令，与copy的区别是ADD 可以复制远程文件 ADD &lt;src&gt;... &lt;dest&gt; src 代表要复制的路径，dest代表目标路径 ENV 设置环境变量 ENV &lt;key&gt; &lt;value&gt; VOLUME 可实现挂载功能，可以将本地文件夹或者其他容器中的文件夹挂在到这个容器中 VOLUME /var/log /var/db 关于 docker-compose部署Redis &amp; Redis 集群docker-compose createdocker-compose up -d mysql &amp; mysql 集群","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://sunjx93.com/tags/linux/"},{"name":"docker","slug":"docker","permalink":"http://sunjx93.com/tags/docker/"}]},{"title":"netty 总结一下","slug":"netty","date":"2019-03-22T08:00:09.000Z","updated":"2019-05-05T08:30:38.753Z","comments":true,"path":"2019/03/22/netty/","link":"","permalink":"http://sunjx93.com/2019/03/22/netty/","excerpt":"自己有个毛病，写笔记的时候不知道从哪里开始说起…以工作中用到的tcp为例子，总结一下netty的用法和坑。","text":"自己有个毛病，写笔记的时候不知道从哪里开始说起…以工作中用到的tcp为例子，总结一下netty的用法和坑。 我是假的目录 0.0 : 服务端启动 怎么写逻辑处理类handler 持有合法channel以及发送消息 超时策略的处理方式及注意事项 拆包/粘包处理思路 客户端异常情况的重连方式 如何使用netty开发websocket端 如何用客户端代码搞jmeter测试高访问量下服务端抗压能力 netty 多服务端的开发思路 剩下的一些坑（crc8 ） 1.服务端启动 ServerBootstrap这个类代表一个socket服务，创建它，然后把它放在服务端的容器中。 12345678910111213ServerBootstrap b = new ServerBootstrap();// 这里的EventLoopGroup 可以设置数量b.group(new EventLoopGroup(),new EventLoopGroup()) .channel(NioServerSocketChannel.class) // 放置自己的channelHandler,如果想使用spring 上下文也可以autowired .childHandler(new MyChannelHandler()); // 这里是netty的配置属性Map&lt;ChannelOption&lt;?&gt;, Object&gt; tcpChannelOptions = (...);Set&lt;ChannelOption&lt;?&gt;&gt; keySet = tcpChannelOptions.keySet();for (@SuppressWarnings(&quot;rawtypes&quot;) ChannelOption option : keySet) &#123; b.option(option, tcpChannelOptions.get(option));&#125; 服务端的配置属性我用的不多，大概是三个 属性放置在ChannelOption作为key的Map中，在声名ServerBootstrap时放入ServerBootstrap.option(?) 方法中 我的channelOption: name value 解释 ChannelOption.SO_KEEPALIVE true Socket参数，连接保活，默认值为False。启用该功能时，TCP会主动探测空闲连接的有效性。可以将此功能视为TCP的心跳机制，需要注意的是：默认的心跳间隔是7200s即2小时。Netty默认关闭该功能。 ChannelOption.SO_BACKLOG 1 Socket参数，服务端接受连接的队列长度，如果队列已满，客户端连接将被拒绝。默认值，Windows为200，其他为128。 ChannelOption.TCP_NODELAY true TCP参数，立即发送数据，默认值为Ture（Netty默认为True而操作系统默认为False）。该值设置Nagle算法的启用，改算法将小的碎片数据连接成更大的报文来最小化所发送的报文的数量，如果需要发送一些较小的报文，则需要禁用该算法。Netty默认禁用该算法，从而最小化报文传输延时。 具体的配置可以看Api文档，或者看这篇文章： netty Channel Option 2.怎么写逻辑处理类handler 先介绍一下我们项目中的通信规则：数据消息是一串byte数组，校验方式用的CRC8，分割符是十六进制的FFFF,占据两个byte格式是这样的： 头部 内容 crc8 结尾 长度(byte)： 1 x 1 2 简单的ChannelHandler 代码：1234567891011121314151617181920212223242526@ChannelHandler.Sharable // 这个注解的意思是handler可以被多个channel安全的共享public class MyChannelHandler extends ChannelInboundHandlerAdapter&#123; // 主要的消息接收的方法，所有的消息都走的这个方法 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123;&#125; // 字面意思，代表消息接收完毕时调用的方法 @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123;&#125; // 发生异常时调用该方法 @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123;&#125; // socket最初连接的方法 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123;&#125; // socket断开时调用该方法 @Override public void channelInactive(ChannelHandlerContext ctx) &#123;&#125; // socket 通信超时时调用该方法 @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123;&#125;&#125; GIAO！一个简单的channelHandler 大概就是上面这个样子，这里有几个需要注意的地方： ChannelHandler可以继承ChannelInboundHandlerAdapter，或者是它的子类SimpleChannelInboundHandler&lt;T&gt; SimpleChannelInboundHandler对父类进行了简单的封装，当使用SimpleChannelInboundHandler时需要规范消息类型&lt;T&gt;，一般是ByteBuf。 当使用ChannelInboundHandlerAdapter时要注意在接受完消息后，应该把msg手动释放掉，而SimpleChannelInboundHandler已经帮助你做了这个事情。 使用方法:ReferenceCountUtil.release(msg);进行释放，其实只要是使用了ByteBuf，都要进行这个操作，这里的原因主要涉及netty对于堆外内存的使用了，有兴趣的可以自行百度。 我们可以根据头部区分消息类型，根据类型不同进行不同的逻辑处理方法。 假如你有类似数组、Hash表存取的操作，最好把逻辑处理这部分操作放到内存队列中去处理。 netty虽然是全异步的，但是你的服务端却并不是，假如你有类似数组、Hash表存取的操作，还是应该放到队列中去，或者你应该把这里所有操作Jvm内存数据结构的操作都改成线程安全的。 ps:这里用的内存队列是Disruptor,还挺好用的，以后会写一篇关于disruptor的总结。 所有处理逻辑放入队列有好处也有坏处，当你真的这么干的时候，有可能线上服务器环境会显示你的netty很稳定，cpu开销等等都比较理想，然而事实上很可能并非如此。 一个channel从注册到断开的顺序到底是怎样的 1) channelRegistered 2) channelActive 3) channelInactive 4) channelUnregistered 超时处理userEventTriggered 到底应该咋处理： 超时策略可以处理一些客户端网络突然断开时的问题netty可以设置客户端通信时间——读超时，写超时以及读写超时当发生该类超时的时候，我们就可以在服务端进行主动把channel踢掉线的这种操作。下文中详细写~ 3.持有合法channel以及发送消息 当客户端在建立连接之后，经过了一系列认证判断啥的过程，一个合法的长连接应该被合理的引用起来，方便进行下一步的业务逻辑操作。 ChannelHandlerContext可以被理解为一个socket的上下文，拿到了它，就掌握了这个连接的通信。 so，可以放到hash中，数组中，或者跟其他客户端属性一起封装到一个类中，都可以。。。。 单发消息 ChannelHandlerContext.writeAndFlush() 单发消息回调 可能有些聪明的小朋友发现ChannelHandlerContext.writeAndFlush()返回的结果是一个channelFuture 回调类， 就天真的以为可以使用channelFuture.isSuccess() 方法验证这条消息是否真的给对方发送过去了。 NO,isSuccess只回调成功放置消息至tcp缓冲区！！！ 也就是说即便是客户端直接断网，服务端这里发送消息后拿到的 success 依旧是 true 那特么怎么判断发送消息是否成功？ 一种思路是通过判断 Channel 上绑定的时间与当前时间只差是否超过了阈值，具体的实现我会以后整理一下。 群发消息广播 有的时候业务并不单单仅仅要求点对点发送，而是很多人同时收到某个消息，比如游戏中位置的移动，这是要同时告知所有场景内用户的。 使用 ChannelGroup 1234ChannelGroup channels =new DefaultChannelGroup(GlobalEventExecutor.INSTANCE);// 这相当于把这个连接放置到这个场景中channels.add(你自己的channel)channels.writeAndFlush(); 就酱 4.超时策略的处理方式及注意事项 使用IdleStateHandler 1234567891011121314151617181920212223242526public class TcpProtocolInitalizer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); // 这里的“30,30，60”分别代表读超时，写超时以及读写超时时间，单位是秒 pipeline.addLast(&quot;ping&quot;, new IdleStateHandler(30, 30, 60, TimeUnit.SECONDS)); // 这段代码主要是声名结尾关键字，这样netty方便对多条指令进行拆包 byte[] bytes = new byte[2]; bytes[0] = (byte)0xFF; bytes[1] = (byte)0xFF; ByteBuf delimeter = Unpooled.copiedBuffer(bytes); try &#123; // 这里使用了DelimiterBasedFrameDecoder这个拆包器，也有String类型的等等 pipeline.addLast(new DelimiterBasedFrameDecoder(1024, delimeter)); int port = ch.localAddress().getPort(); System.out.println(&quot;ch.localAddress().getPort()==&quot; + port); if (port == tcpConfig.getTcpPort()) &#123; // 我们在这里关联自己的逻辑channelHandler业务 pipeline.addLast(&quot;handler&quot;, serverHandler); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 这个类要在ServerBootstrap 启动之前注入initChannel()方法里，这样就会在handler中在userEventTriggered中收到超时的回调了。 5.拆包/粘包 处理思路 其实主要思路还是如何让netty知道一段指令到哪里才是结束~~~ 定长消息 关键字作为结束符，要注意关键字需要避免重复 ——保证唯一性 自定义消息格式，需要自己实现解码器 拆包器在初始化serverbootstrap 时生效 6.客户端异常情况的重连方式 几种思路： 客户端主动发起连接请求，复用eventloopgroup, Bootstrap 创建新对象并覆盖到老的引用上， 然后 Bootstrap 重新进行连接 ，该动作可以不限制重连次数- 7.如何使用netty开发websocket端 不想写了，偷懒了 8.如何用客户端代码搞jmeter测试高访问量下服务端抗压能力 利用jmeter进行代码测试在开发中还是很重要的，我临时写了一套代码放在git上了：https://github.com/Drazen08/clientDemo.git 具体步骤 引入依赖 12345678910111213&lt;!-- https://mvnrepository.com/artifact/org.apache.jmeter/ApacheJMeter_core --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.jmeter&lt;/groupId&gt; &lt;artifactId&gt;ApacheJMeter_core&lt;/artifactId&gt; &lt;version&gt;5.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.jmeter/ApacheJMeter_java --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.jmeter&lt;/groupId&gt; &lt;artifactId&gt;ApacheJMeter_java&lt;/artifactId&gt; &lt;version&gt;5.0&lt;/version&gt;&lt;/dependency&gt; 声明主程序,继承AbstractJavaSamplerClient的一个类 把代码打成jar包，注意需要把所有依赖都打入jar包 在jmeter 内创建线程组… 9.netty 多服务端的开发思路10.剩下的一些坑（crc8）","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://sunjx93.com/tags/Java/"},{"name":"netty","slug":"netty","permalink":"http://sunjx93.com/tags/netty/"}]},{"title":"Cas 单点登录相关","slug":"cas","date":"2018-06-03T08:52:09.000Z","updated":"2019-03-25T01:58:52.154Z","comments":true,"path":"2018/06/03/cas/","link":"","permalink":"http://sunjx93.com/2018/06/03/cas/","excerpt":"这几天换了工作，事情一下子多了起来，前公司十分给力的只给了我400多的应付职工薪酬，心态炸了。不说别的，这几天重点研究了cas的单点登录，总结一下。","text":"这几天换了工作，事情一下子多了起来，前公司十分给力的只给了我400多的应付职工薪酬，心态炸了。不说别的，这几天重点研究了cas的单点登录，总结一下。 CAS - Central Authentication Service CAS是一个单点登录框架，通俗理解为一个应用登录了，其他被授权的应用不用再登录。 比如，A系统登录了之后，B系统就可以跳过登录，转而进入系统内。于是问题来了：在实现cas单点登录之前，我首先要实现两个系统的多数据源配置，把登录相关表设为一个共有的数据源。关于多数据源配置我另起了一篇○|￣|_ 事实上，使用cas单点登录时，相当于跳过原项目的登录过程，把登录的功能转嫁给cas服务器来实现。 1.下载由于cas是开源的，所以直接在官网 下载源码就可以。下载下来是这样子的： 其实只需要用到一个包，就可以实现简单的单点登录：cas-server-core，并且这个包下源码的编译文件最后是要放到应用服务器里面的。 把\\cas-server-4.0.0\\modules 文件夹下的cas-server-webapp-4.0.0.war改名为cas.war，并放在tomcat目录下webapps中，并启动tomcat。 此时webapps目录下已经解压了cas文件夹，可以进行下一步了。 2.对cas-server-core 源码进行修改 由于不同的项目都有着自己的密码加密规则，所以需要对cas-server-core包下的源码进行修改： 上代码： 修改\\webapps\\cas\\WEB-INF下的deployerConfigContext.xml 替换primaryAuthenticationHandler 的 bean12345&lt;bean id=&quot;primaryAuthenticationHandler&quot; class=&quot;com.distinct.cas.jdbc.QueryDatabaseAuthenticationHandler&quot;p:dataSource-ref=&quot;dataSource&quot;p:passwordEncoder-ref=&quot;passwordEncoder&quot;p:sql=&quot;select password from sys_user where username=? and status = 1&quot; /&gt; 新增123456789101112&lt;bean id=&quot;dataSource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot; &gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://192.168.0.107:3306/sys_blueroc_db?autoReconnect=true&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;passwordEncoder&quot; class=&quot;org.jasig.cas.authentication.handler.DefaultPasswordEncoder&quot; c:encodingAlgorithm=&quot;MD5&quot; p:characterEncoding=&quot;UTF-8&quot; /&gt; bean dataSource主要是定义连接用户表数据库的配置，QueryDatabaseAuthenticationHandler类就是对用户校验的处理类,在server-core 源码包中新增： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package com.distinct.cas.jdbc;import org.jasig.cas.authentication.HandlerResult;import org.jasig.cas.authentication.PreventedException;import org.jasig.cas.authentication.UsernamePasswordCredential;import org.jasig.cas.authentication.handler.support.AbstractUsernamePasswordAuthenticationHandler;import org.jasig.cas.authentication.principal.SimplePrincipal;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.jdbc.datasource.DriverManagerDataSource;import org.springframework.stereotype.Component;import javax.security.auth.login.FailedLoginException;import java.security.GeneralSecurityException;/** * @author sunjx * @date 2018/5/28 16:23 **/@Component(value = &quot;primaryAuthenticationHandler&quot;)public class QueryDatabaseAuthenticationHandler extends AbstractUsernamePasswordAuthenticationHandler&#123; private Logger logger = LoggerFactory.getLogger(QueryDatabaseAuthenticationHandler.class); @Autowired private DriverManagerDataSource dataSource; // 注入deployerConfigContext.xml 的查询sql @Autowired private String sql; /** * Authenticates a username/password credential by an arbitrary strategy. * * @param transformedCredential the credential object bearing the transformed username and password. * @return HandlerResult resolved from credential on authentication success or null if no principal could be resolved * from the credential. * @throws GeneralSecurityException On authentication failure. * @throws PreventedException On the indeterminate case when authentication is prevented. */ protected final HandlerResult authenticateUsernamePasswordInternal(final UsernamePasswordCredential transformedCredential) throws GeneralSecurityException, PreventedException &#123; //UsernamePasswordCredential参数包含了前台页面输入的用户信息 String username = getPrincipalNameTransformer().transform(transformedCredential.getUsername()); String password = transformedCredential.getPassword(); //认证用户名和密码是否正确 final String encryptedPassword = this.getPasswordEncoder().encode(password,username); logger.info(&quot;pwd:&quot;+encryptedPassword + &quot;////////////////////////////////////&quot;); System.out.println(&quot;pwd:&quot;+encryptedPassword + &quot;////////////////////////////////////&quot;); try &#123; JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource); if(encryptedPassword.equals(jdbcTemplate.queryForObject(sql, new Object[]&#123;username&#125;,String.class)))&#123; return createHandlerResult(transformedCredential, new SimplePrincipal(username), null); &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; throw new FailedLoginException(); &#125; public void setDataSource(DriverManagerDataSource dataSource) &#123; this.dataSource = dataSource; &#125; public DriverManagerDataSource getDataSource() &#123; return dataSource; &#125; public void setSql(String sql) &#123; this.sql = sql; &#125; public String getSql() &#123; return sql; &#125;&#125; 服务端创建安全证书： cmd 控制台进入某给文件路径（同linux） 生成证书keytool -genkey -alias cas(别名) -keyalg RSA -keystore D:/keys/smallkey（证书路径）2.导出证书keytool -export -file d:/keys/small.crt -alias smalllove -keystore d:/keys/smallkey3.导入证书到jdk中keytool -import -keystore C:\\Java\\jdk1.6.0_21\\lib\\security\\cacerts -file D:/keys/small.crt -alias cas 在客户端shiroConfig中定义cas的服务器路径 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165 public static final String loginUrl = &quot;http://localhost:8443/cas/login?service=你的项目路径&quot;; /** * 注册单点登出filter * @return */ @Bean public FilterRegistrationBean singleSignOutFilter()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setName(&quot;singleSignOutFilter&quot;); bean.setFilter(new SingleSignOutFilter()); bean.addUrlPatterns(&quot;/*&quot;); bean.setEnabled(true); //bean.setOrder(Ordered.HIGHEST_PRECEDENCE); return bean; &#125; /** * 定义casfilter继承`org.apache.shiro.cas.CasFilter` * * @return * @author * @create */ @Bean(name = &quot;casFilter&quot;) public CasFilter getCasFilter() &#123; MyCasFilter casFilter = new MyCasFilter(); casFilter.setName(&quot;casFilter&quot;); casFilter.setEnabled(true); casFilter.setLoginUrl(casLoginUrl); casFilter.setSuccessUrl(loginSuccessUrl); // 登录失败后跳转的URL，也就是 Shiro 执行 CasRealm 的 doGetAuthenticationInfo 方法向CasServer验证tiket casFilter.setFailureUrl(loginUrl);// 我们选择认证失败后再打开登录页面 return casFilter; &#125; /** * 该过滤器负责用户的认证工作，必须启用它 * @return */ @Bean public FilterRegistrationBean casAuthenticationFilter() &#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.setFilter(new AuthenticationFilter());// AuthenticationFilter t = new AuthenticationFilter(); filterRegistrationBean.addUrlPatterns(&quot;/*&quot;); filterRegistrationBean.addInitParameter(&quot;casServerLoginUrl&quot;,ShiroConfig.casLoginUrl); //cas 服务器登录 filterRegistrationBean.addInitParameter(&quot;serverName&quot;,ShiroConfig.shiroServerUrlPrefix); // 客户端服务器地址 return filterRegistrationBean; &#125; /** * 该过滤器负责对Ticket的校验工作，必须启用它 * @return */ @Bean public FilterRegistrationBean casFilterRegistrationBean() &#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.addUrlPatterns(&quot;/*&quot;); filterRegistrationBean.setFilter(new Cas20ProxyReceivingTicketValidationFilter()); filterRegistrationBean.addInitParameter(&quot;serverName&quot;,ShiroConfig.shiroServerUrlPrefix); // cas 服务器地址 filterRegistrationBean.addInitParameter(&quot;casServerUrlPrefix&quot;,ShiroConfig.casServerUrlPrefix); // 客户端服务器地址 return filterRegistrationBean; &#125; /** * 该过滤器负责实现HttpServletRequest请求的包裹， * 比如允许开发者通过HttpServletRequest的getRemoteUser()方法获得SSO登录用户的登录名 * 可选配置 * @return */ @Bean public FilterRegistrationBean httpServletRequestWrapperFilter() &#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.addUrlPatterns(&quot;/*&quot;); filterRegistrationBean.setFilter(new HttpServletRequestWrapperFilter()); return filterRegistrationBean; &#125; /** * 该过滤器使得开发者可以通过org.jasig.cas.client.util.AssertionHolder来获取用户的登录名。 * AssertionHolder.getAssertion().getPrincipal().getName()。 * @return */ @Bean public FilterRegistrationBean assertionThreadLocalFilter() &#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.addUrlPatterns(&quot;/*&quot;); filterRegistrationBean.setFilter(new AssertionThreadLocalFilter()); return filterRegistrationBean; &#125; /** * 注册单点登出listener * @return */ @Bean public ServletListenerRegistrationBean singleSignOutHttpSessionListener()&#123; ServletListenerRegistrationBean bean = new ServletListenerRegistrationBean(); bean.setListener(new SingleSignOutHttpSessionListener());// bean.setName(&quot;&quot;); //默认为bean name bean.setEnabled(true); //bean.setOrder(Ordered.HIGHEST_PRECEDENCE); //设置优先级 return bean; &#125; // 然后声明shiro 的cas登录的realm @Bean public MyShiroCasRealm myShiroCasRealm(EhCacheManager cacheManager) &#123; MyShiroCasRealm realm = new MyShiroCasRealm (); realm.setCacheManager(cacheManager); return realm; &#125; // 在返回SecurityManager的bean内加入MyShiroCasRealm： @Bean public SecurityManager securityManager() &#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); Collection collection = new ArrayList(); ((ArrayList) collection).add(userRealm()); ((ArrayList) collection).add(myShiroCasRealm(ehCacheManager())); //设置realm. securityManager.setRealms(collection); // 自定义缓存实现 使用redis if (Constant.CACHE_TYPE_REDIS.equals(cacheType)) &#123; securityManager.setCacheManager(cacheManager()); &#125; else &#123; securityManager.setCacheManager(ehCacheManager()); &#125; securityManager.setSessionManager(sessionManager()); return securityManager; &#125; &lt;!-- 最后，加入上面已经声明的过滤器 --&gt; @Bean ShiroFilterFactoryBean shiroFilterFactoryBean(SecurityManager securityManager) &#123; Map&lt;String, Filter&gt; filters = new HashMap&lt;&gt;(); filters.put(&quot;casFilter&quot;, getCasFilter()); filters.put(&quot;authenticationFilter&quot;, casAuthenticationFilter().getFilter()); filters.put(&quot;cas20ProxyReceivingTicketValidationFilter&quot;, casFilterRegistrationBean().getFilter()); filters.put(&quot;httpServletRequestWrapperFilter&quot;, httpServletRequestWrapperFilter().getFilter()); filters.put(&quot;assertionThreadLocalFilter&quot;, assertionThreadLocalFilter().getFilter()); ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); shiroFilterFactoryBean.setSecurityManager(securityManager); shiroFilterFactoryBean.setLoginUrl(loginUrl); shiroFilterFactoryBean.setSuccessUrl(loginSuccessUrl); shiroFilterFactoryBean.setUnauthorizedUrl(unauthorizedUrl); shiroFilterFactoryBean.setFilters(filters); LinkedHashMap&lt;String, String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;&gt;(); filterChainDefinitionMap.put(&quot;/css/**&quot;, &quot;anon&quot;); filterChainDefinitionMap.put(&quot;/api/**&quot;, &quot;anon&quot;); filterChainDefinitionMap.put(&quot;/**&quot;, &quot;authc&quot;); shiroFilterFactoryBean.setFilterChainDefinitionMap(filterChainDefinitionMap); return shiroFilterFactoryBean; &#125; 编译server-core 源码，放在tomcat-8.5.30\\webapps\\cas\\WEB-INF\\classes下 然后，可以试着运行一下tomcat，期间可能会有依赖包确实，把下载的jar包放到tomcat-8.5.30\\webapps\\cas\\WEB-INF\\lib 下。 如果访问http://localhost:8443/cas/login 出现如下页面，则证明部署成功了。 2.cas 修改登录样式假如，你觉得上面的登录样式太丑了（事实上的确很丑..），那我们可以去修改一下登录的样式： 算了，贴个链接吧，我太懒了QAQ cas4.2.7定制登录页面样式(并且让页面默认使用中文提示)","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://sunjx93.com/tags/Java/"},{"name":"CAS单点登录","slug":"CAS单点登录","permalink":"http://sunjx93.com/tags/CAS单点登录/"}]},{"title":"Mysql 分页整理","slug":"fenye","date":"2018-04-10T05:52:09.000Z","updated":"2018-04-24T08:39:10.201Z","comments":true,"path":"2018/04/10/fenye/","link":"","permalink":"http://sunjx93.com/2018/04/10/fenye/","excerpt":"轻量数据与大量数据的分页完全是两回事，如果没有很好地进行优化，很可能会导致性能的直线下降。现在对mysql分页做一个简单的小整理…","text":"轻量数据与大量数据的分页完全是两回事，如果没有很好地进行优化，很可能会导致性能的直线下降。现在对mysql分页做一个简单的小整理… 最简单的分页 select * from content order by id desc limit 0, 10 当数据量多了一些的时候：select * from content order by id desc limit 1000000, 10 当数据量比较大的时候，这样分页的方案会导致最后几页的查询速度下降。 所以SELECT * FROM table WHERE id &gt;= (SELECT id FROM table LIMIT 1000000, 1) LIMIT 10; 因为id是拥有索引的主键，所以，效率会比纯limit高一些 什么是更优解？SELECT * FROM table WHERE id BETWEEN 1000000 AND 1000010; 另：如果找寻的id并不连续，可以先找出id，再用in的方式查询： SELECT * FROM table WHERE id IN(10000, 100000, 1000000...); 另一种方式： FOUND_ROWS() 使用MySql中的函数FOUND_ROWS()，在SELECT中可以得到两个结果： 得到Limit的内容 得到去除Limit以后所有行数 SELECT语句中经常可能用LIMIT限制返回行数。有时候可能想要知道如果没有LIMIT会返回多少行，但又不想再执行一次相同语句。那么，在SELECT查询中包含SQL_CALC_FOUND_ROWS选项，然后执行FOUND_ROWS()就可以了： select SQL_CALC_FOUND_ROWS * FROM tbl_name WHERE id &gt; 100 LIMIT 10; SELECT FOUND_ROWS(); 如果在前一条语句中使用SQL_CALC_FOUND_ROWS选项，FOUND_ROWS()将返回第一条语句没有LIMIT时返回的行数。 如果在前一条语句中没有使用SQL_CALC_FOUND_ROWS选项，FOUND_ROWS()将返回前一条语句实际返回的行数。 如果使用 SELECT SQL_CALC_FOUND_ROWS，MySQL必须计算所有结果集的行数。尽管这样，总比再执行一次不使用LIMIT的查询要快多了吧，因为那样结果集要返回客户端滴。（另外：应该不单是没有将结果集返回的原因，还有原因可能是比如LIKE之类比较费劲的SQL不需要再去劳累一次。） – 注意下面语句中的条件 LIKE SELECT SQL_CALC_FOUND_ROWS * FROM tbl_name WHERE Name LIKE ‘%string%’ id &gt; 100 LIMIT 10; SELECT FOUND_ROWS(); – 上面语句等价于下面语句，但性能方面应该提升非常非常的明显： SELECT COUNT(*) FROM tbl_name WHERE Name LIKE ‘%string%’ ; SELECT * FROM tbl_name WHERE Name LIKE ‘%string%’ id &gt; 100 LIMIT 10;","categories":[],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://sunjx93.com/tags/Mysql/"}]},{"title":"自定义注解及拓展","slug":"annotation","date":"2018-04-07T08:52:09.000Z","updated":"2019-03-29T05:31:33.516Z","comments":true,"path":"2018/04/07/annotation/","link":"","permalink":"http://sunjx93.com/2018/04/07/annotation/","excerpt":"自定义注解的用法，会了的话定义一个@Override同名注解什么的…","text":"自定义注解的用法，会了的话定义一个@Override同名注解什么的… 1.首先要了解自定义注解的两个元素（元注解） 用来声明注解本身的行为 @Target 用来声明注解可以被添加在哪些类型的元素上,如类型、方法和域等。 传入参数|描述–|–TYPE|METHOD|CONSTRUCTOR |FIELD| @Retention : 声明注解的保留策略 关键字|描述 –|– CLASS|声明注解保存在类文件 RUNTIME|声明注解保存在JVM运行时 SOURCE|声明注解保存在源码中 @Documented 指明拥有这个注解的元素可以被javadoc此类的工具文档化。这种类型应该用于注解那些影响客户使用带注释的元素声明的类型。如果一种声明使用Documented进行注解，这种类型的注解被作为被标注的程序成员的公共API。 @Inherited 指明该注解类型被自动继承。如果用户在当前类中查询这个元注解类型并且当前类的声明中不包含这个元注解类型，那么也将自动查询当前类的父类是否存在Inherited元注解，这个动作将被重复执行知道这个标注类型被找到，或者是查询到顶层的父类。 Java内建注解Java提供了三种内建注解。 @Override 当我们想要复写父类中的方法时，我们需要使用该注解去告知编译器我们想要复写这个方法。这样一来当父类中的方法移除或者发生更改时编译器将提示错误信息。 @Deprecated 当我们希望编译器知道某一方法不建议使用时，我们应该使用这个注解。Java在javadoc 中推荐使用该注解，我们应该提供为什么该方法不推荐使用以及替代的方法。 @SuppressWarnings 这个仅仅是告诉编译器忽略特定的警告信息，例如在泛型中使用原生数据类型。它的保留策略是SOURCE,并且被编译器丢弃。2.开始 a.以此在类中声明一个自定义注解@Retention(RetentionPolicy.RUNTIME) @Target(ElementType.FIELD) public @interface AnnotationDemo { // 声明一个注解 String name(); int age() default 0; } 其中，finished这个注解的默认值是0,也就是可以设置默认值！ b.在某项中注入值public class AnnotationPriv { @AnnotationDemo(name = &quot;Tom&quot;,age = 19) private String id; } c.设置注解的逻辑处理public class AnnotationUtilDemo { public static void getFruitInfo(Class&lt;?&gt; clazz){ String personName =&quot;名称：&quot;; String personAge = &quot;年龄&quot;; Field[] fields = clazz.getDeclaredFields(); for(Field field :fields){ if(field.isAnnotationPresent(AnnotationDemo.class)){ AnnotationDemo annotationDemo = (AnnotationDemo) field.getAnnotation(AnnotationDemo.class); personName = personName+annotationDemo.name(); personAge = personAge + annotationDemo.age(); System.out.println(personName); System.out.println(personAge); } } } } d.运行123public static void main(String[] args) &#123; AnnotationUtilDemo.getFruitInfo(AnnotationPriv.class);&#125; e.得出结果名称：Tom 年龄19 花式注解 现在我有个奇葩需求，两个类同时实现了一个interface,蓝后我要在这两个类上声明一个带值的注解，通过指定值来指定具体的实现类。 谁知道当时我闲的蛋疼的什么奇葩脑洞，可能真实开发中用不到这个玩意，但是开展一下总是好的。 a.声明一个注解12345@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface ModeCode &#123; int value() default 1;&#125; b.新建一个interface，两个实现类123public interface SayHi&#123; String SayHi();&#125; 1234@ModeCode(1)public class sayHiA implements SayHi&#123; ...&#125; 1234@ModeCode(2)public class sayHiB implements SayHi&#123; ...&#125; 这个时候应该怎么搞啊我需要获取这个interface的全部实现类啊！！ google 有一个工具包 auto-service这个第三方工具可以找到interface下的所有实现类 123456ServiceLoader&lt;S&gt; loader = ServiceLoader.load(SayHi.class); for (S s : loader) &#123; if (s.getClass().getAnnotation(ModeCode.class).value() == getMode()) &#123; return (S) ApplicationContextRegister.getBean(s.getClass()); &#125; &#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://sunjx93.com/tags/Java/"},{"name":"Annotation","slug":"Annotation","permalink":"http://sunjx93.com/tags/Annotation/"}]},{"title":"Bean 生命周期","slug":"LifeBean","date":"2018-04-07T08:52:09.000Z","updated":"2018-04-24T09:16:54.629Z","comments":true,"path":"2018/04/07/LifeBean/","link":"","permalink":"http://sunjx93.com/2018/04/07/LifeBean/","excerpt":"Spring Bean 的生命周期在面试中被问到不止一次了，每次结结巴巴的说出来好没面子呀~","text":"Spring Bean 的生命周期在面试中被问到不止一次了，每次结结巴巴的说出来好没面子呀~ Spring Bean 作用域、生命周期Bean的作用域 Spring 3中为Bean定义了5中作用域，分别为singleton（单例）、prototype（原型）、request、session和global session，5种作用域说明如下： singleton：单例模式，Spring IoC容器中只会存在一个共享的Bean实例，无论有多少个Bean引用它，始终指向同一对象。Singleton作用域是Spring中的缺省（默认）作用域，也可以显示的将Bean定义为singleton模式，配置为： 1&lt;bean id=&quot;userDao&quot; class=&quot;com.ioc.UserDaoImpl&quot; scope=&quot;singleton&quot;/&gt; prototype:原型模式，每次通过Spring容器获取prototype定义的bean时，容器都将创建一个新的Bean实例，每个Bean实例都有自己的属性和状态，而singleton全局只有一个对象。根据经验，对有状态的bean使用prototype作用域，而对无状态的bean使用singleton作用域。 request：在一次Http请求中，容器会返回该Bean的同一实例。而对不同的Http请求则会产生新的Bean，而且该bean仅在当前Http Request内有效。 1&lt;bean id=&quot;loginAction&quot; class=&quot;com.cnblogs.Login&quot; scope=&quot;request&quot;/&gt; 针对每一次Http请求，Spring容器根据该bean的定义创建一个全新的实例，且该实例仅在当前Http请求内有效，而其它请求无法看到当前请求中状态的变化，当当前Http请求结束，该bean实例也将会被销毁。 session：在一次Http Session中，容器会返回该Bean的同一实例。而对不同的Session请求则会创建新的实例，该bean实例仅在当前Session内有效。1&lt;bean id=&quot;userPreference&quot; class=&quot;com.ioc.UserPreference&quot; scope=&quot;session&quot;/&gt; 同Http请求相同，每一次session请求创建新的实例，而不同的实例之间不共享属性，且实例仅在自己的session请求内有效，请求结束，则实例将被销毁。 global Session：在一个全局的Http Session中，容器会返回该Bean的同一个实例，仅在使用portlet context时有效。 Bean的生命周期 Spring容器可以管理singleton作用域下Bean的生命周期，在此作用域下，Spring能够精确地知道Bean何时被创建，何时初始化完成，以及何时被销毁。 对于prototype作用域的Bean，Spring只负责创建，当容器创建了Bean的实例后，Bean的实例就交给了客户端的代码管理，Spring容器将不再跟踪其生命周期，并且不会管理那些被配置成prototype作用域的Bean的生命周期 Bean的生命周期： 1、实例化一个Bean－－也就是我们常说的new 2、按照Spring上下文对实例化的Bean进行配置－－也就是IOC注入； 3、如果这个Bean已经实现了BeanNameAware接口，会调用它实现的setBeanName(String)方法，此处传递的就是Spring配置文件中Bean的id值 4、如果这个Bean已经实现了BeanFactoryAware接口，会调用它实现的setBeanFactory(setBeanFactory(BeanFactory)传递的是Spring工厂自身（可以用这个方式来获取其它Bean，只需在Spring配置文件中配置一个普通的Bean就可以）； 5、如果这个Bean已经实现了ApplicationContextAware接口，会调用setApplicationContext(ApplicationContext)方法，传入Spring上下文（同样这个方式也可以实现步骤4的内容，但比4更好，因为ApplicationContext是BeanFactory的子接口，有更多的实现方法）； 6、如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessBeforeInitialization(Object obj, String s)方法，BeanPostProcessor经常被用作是Bean内容的更改，并且由于这个是在Bean初始化结束时调用那个的方法，也可以被应用于内存或缓存技术；主要是我们如果需要在spring中增加自己的逻辑 7、如果Bean在Spring配置文件中配置了init-method属性会自动调用其配置的初始化方法。 8、如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessAfterInitialization(Object obj, String s)方法； 注：以上工作完成以后就可以应用这个Bean了，那这个Bean是一个Singleton的，所以一般情况下我们调用同一个id的Bean会是在内容地址相同的实例，当然在Spring配置文件中也可以配置非Singleton，这里我们不做赘述。 9、当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，会调用那个其实现的destroy()方法； 10、最后，如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的销毁方法。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://sunjx93.com/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://sunjx93.com/tags/Spring/"}]},{"title":"Linux 下oracle的数据恢复以及数据库命令行安装","slug":"linux_oracle","date":"2017-11-07T08:52:09.000Z","updated":"2018-04-24T09:17:02.507Z","comments":true,"path":"2017/11/07/linux_oracle/","link":"","permalink":"http://sunjx93.com/2017/11/07/linux_oracle/","excerpt":"由于项目在运行过程中所需的空间越来越大，最终Linux的表分区使用比例达到了100%，导致项目无法正常登录以及无法正常访问数据库，原因主要是表空间过大。在备份了dbf文件后之后，由于操作有误，误删了oracle的一个redo日志，于是不得不重装oracle 因为表空间主要存储的都是用户上传的文件数据，所以必须恢复","text":"由于项目在运行过程中所需的空间越来越大，最终Linux的表分区使用比例达到了100%，导致项目无法正常登录以及无法正常访问数据库，原因主要是表空间过大。在备份了dbf文件后之后，由于操作有误，误删了oracle的一个redo日志，于是不得不重装oracle 因为表空间主要存储的都是用户上传的文件数据，所以必须恢复 ps: 因为服务器上相关的配置文件都配置过一遍，所以不用重新配置 1. 把dbf文件通过恢复工具导入到测试环境在网上找了好多数据库恢复的软件，但都是收费的…QAQ 最后选择一个叫odu的工具，非图形化界面，需要注意的是配置文件的格式需要规范一点，具体的操作步骤可以看： 老熊的博客 再贴一个odu的下载 总之经过一番操作之后终于把数据跑到自己电脑上了，随后我们要进行的是linux在oracle的命令行安装。 2. oracle 静默安装 由于这个项目的运行环境是内网环境，所以一些yum什么的工具都暂时用不了，当时也没有什么时间去鼓捣图形化之类的东西了，就试着用xshell进行了命令行安装。 a. 下载oracle for linux 的zip安装包上传到机器上并解压，要注意文件的权限不能是root，应该是oracle，也就是用作数据库的权限账号 b. 使用oracle用户登录并解压到一个目录下 unzip filenamec. 解压完之后会有一个database目录我们要找到/oracle/database/response下的三个.rsp 文件，复制到/home/oracle里面，并在这里做一些修改。 首先 是db_install.rsp,这里的改动需要仔细，如果配置错误的话就会报错。 静默安装_db-install.rsp 配置 接下来是dbca.rsp和netca.rsp dbca.rspvi dbca.rsp 修改以下内容 GDBNAME = “ora11g” SID = “ora11g” SYSPASSWORD = “oracle11” SYSTEMPASSWORD = “oracle11” netca.rspvi netca.rsp修改以下内容 INSTALL_TYPE=””custom”” 配置完之后进入database目录下，执行脚本1./runInstaller -silent -responseFile /home/oracle/db_install.rsp 如果一切顺利的话，会提示你the setup completed 之类的，而且会提示你运行两个文件，注意: 这两个文件需要用root用户运行。 运行完成后，可能要退回oracle 的主目录刷新一下.bash_profile1source .bash_profile 成功后就可以看到登录信息里有自己的sid了，这个时候就是常规操作： 12345创建数据库 dbca -silent -cloneTemplate -responseFile ./dbca.rsp创建监听 netca /silent /responseFile /home/oracle/netca.rsp开启oracle监听 lsnrctl start 3 创建oracle 实例 安装好oracle 之后是没有oracle实例的，需要自己去建 创建oracle实例（没错我在偷懒） 总之最后很幸运的没有丢数据，我们一定要做好的是备份！备份！备份！","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://sunjx93.com/tags/Linux/"},{"name":"Oracle","slug":"Oracle","permalink":"http://sunjx93.com/tags/Oracle/"}]},{"title":"Quartz实现定时任务","slug":"Quartz","date":"2017-07-07T08:52:09.000Z","updated":"2018-04-24T09:17:11.840Z","comments":true,"path":"2017/07/07/Quartz/","link":"","permalink":"http://sunjx93.com/2017/07/07/Quartz/","excerpt":"Quartz 最近公司项目中用到了定时任务提醒的功能，Timer在功能上已经无法很好的满足业务，来学习一下Quartz","text":"Quartz 最近公司项目中用到了定时任务提醒的功能，Timer在功能上已经无法很好的满足业务，来学习一下Quartz Quartz 的生命周期 Job接口在execute（JobExecation…）{}中编写逻辑 调用器 执行Job时创建的Job实例，调用完成时，job实例会被释放并回收 JobDetail属性 name 任务名称 group 任务组 默认DEFAULT jobclass jobDetailMap 作用是在execute中传递参数，一般为基本数据类型 ...... JobDataMap&amp;TriggerDataMap: 强力的map型参数，由quzrtz封装，同时实现了map接口 关于Quzrtz的Trigger 作为Quartz的触发器来执行JobTrigger的通用属性 Job Key： 获取JobDetail的key值 startTime： 触发器首次触发的时间 endTime： …停止时间 SimpleTrigger&amp; CronTriggerSimpleTrigger： SimpleTrigge有点类似Java中Timer的一个变体，但是个人觉得在逻辑上比Timer要来的简便 CronTrigger： CronTrigger是Quartz的核心，是一种基于日历的作业调度器 重点： cron表达式：用来配置CronTrigger实例 由7个子表达式组成,描述了时间表的详细信息 格式： [秒] [分] [小时] [日] [月] [年] 注意 []之间有空格符 事例 1234567891011121314151617181920JobDetail jobDetail = JobBuilder.newJob(QuartzJob.class) .withIdentity(&quot;myJob&quot;).build();CronTrigger trigger = (CronTrigger) TriggerBuilder .newTrigger() .withIdentity(&quot;myTrigger&quot;, &quot;group1&quot;) .withSchedule( CronScheduleBuilder.cronSchedule(&quot;* * * * * ?&quot;)) .build();// 创建Scheduler实例SchedulerFactory sfact = new StdSchedulerFactory();Scheduler scheduler = sfact.getScheduler();scheduler.start();System.out.println(&quot;scheduled time is :&quot; + sf.format(scheduler.scheduleJob(jobDetail, trigger)));//scheduler执行两秒后挂起Thread.sleep(2000L);//shutdown(true)表示等待所有正在执行的job执行完毕之后，再关闭scheduler//shutdown(false)即shutdown()表示直接关闭schedulerscheduler.shutdown(false);System.out.println(&quot;scheduler is shut down? &quot; + scheduler.isShutdown()); 其中CronScheduleBuilder.cronSchedule(&quot;* * * * * ?&quot;))这句就是Cron表达式的用法 关于Cron表达式的字符含义: 字段 是否必填 允许值 允许的特殊字符 秒 是 0-59 , - * / 分 是 0-59 , - * / 小时 是 0-23 , - * / 日 是 1-31 , - * ? / L W C 月 是 1-12或者JAN-DEC , - * / 周 是 1-7或者SUN-SAT ,- * ? / L C # 年 否 empty,1970-2099 , - * / 特殊字符 含义 , 表示或 的意思 - 至某事某刻，between的关系 * 表示每， / 表示每隔某时间段触发，比如分的写法:0/5 表示每隔5分钟触发，5/20代表每五分钟触发一次，25,45各触发一次 ? 表示无所谓，不关注，无关紧要 # 第的意思，如6#3每月第三周星期五触发，6代表周五 L 代表最后一 的意思 W 表示有效工作日（周一到周五）， L与W可连用，表示某月最后一个工作日 关于周的换算：1代表周日，6代表周五，以此类推类推 如：0 15 10 ? * 6L 2016-2017: 2016-2017年每月最后一周的周五10点15分执行 年可以不填QAQ ###SchedulerFactory 用来工厂模式来创建Schedular StdSchedulerFactory利用.getScheduler();方法初始创建调度器，参数配置可以采用quartz。properties方法 比较Timer1.无法并发执行：Timer不怎么支持并发 2.因为Timer有且仅有一个后台执行的线程，若一旦爆出RunTimeException，则会停止所有的任务执行 瓶颈：a) 对时效性要求较高的多任务并发作业，虽然支持多任务，但是毕竟是串行接口 b) 对复杂任务的调度不足，不支持定时任务 Quartz1.精细控制流程 2.支持若干任务在上面执行 a)调度功能 b) 持久化机制，数据不会丢失 c) 分布&amp;集群功能","categories":[],"tags":[{"name":"Quartz","slug":"Quartz","permalink":"http://sunjx93.com/tags/Quartz/"},{"name":"Timer","slug":"Timer","permalink":"http://sunjx93.com/tags/Timer/"}]},{"title":"SpringData相关","slug":"sd","date":"2017-05-27T08:52:09.000Z","updated":"2017-05-31T05:53:27.405Z","comments":true,"path":"2017/05/27/sd/","link":"","permalink":"http://sunjx93.com/2017/05/27/sd/","excerpt":"SpringData是原先工作用到了的东西，提供一个一致性的，基于spring的项目，用来访问数据（访问数据库），现在来半预习半复习一下","text":"SpringData是原先工作用到了的东西，提供一个一致性的，基于spring的项目，用来访问数据（访问数据库），现在来半预习半复习一下 特点 可以访问关系型数据库，也可以访问非关系型数据库 目的 减少数据访问层的开发量 其实只需要声明一个持久层的接口 springData 包含的子项目 Spring Data JPA Spring Data MongoDB Spring Data Redis Spring Data Solr (一个全文搜索的东西) 等等….. 1.传统方式访问数据库 jdbc get connection get statement resultSet a)添加依赖123456789101112&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.38&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.10&lt;/version&gt; &lt;/dependency&gt; b)开发JDBCUtil 工具类获取connection 12345678910111213141516171819/** * 获取connection * @return */public static Connection getConnection() throws Exception &#123; //获取配置文件的方法，db.properties 是设置好的配置文件 InputStream input = JDBCUtil.class.getClassLoader().getResourceAsStream(&quot;db.properties&quot;); Properties properties = new Properties(); properties.load(input); String url = properties.get(&quot;jdbc.url&quot;).toString(); String username = properties.get(&quot;jdbc.username&quot;).toString(); String driverClass = properties.get(&quot;user.driverClass&quot;).toString(); Class.forName(driverClass); Connection conn= DriverManager.getConnection(url, username, &quot;&quot;); return conn;&#125; db.properties,灰色的就是没有使用过的 1234user.driverClass = com.mysql.jdbc.Driveruser.username= rootuser.url=jdbc:mysql:///localhostuser.password = 使用 springData jdbc 模板访问数据库 c) DAO 层开发 真的是好复古好复古的写法，DaoImpl1234567891011121314151617181920212223242526272829303132333435/** * 传说中的经典写法？？？？ * @return */ public List&lt;Student&gt; selectAllStudents() &#123; Connection conn = null; PreparedStatement preparedStatement =null; ResultSet resultSet=null; List&lt;Student&gt; li = new ArrayList&lt;Student&gt;(); String sql = &quot;select id ,name,age from tb_student &quot;; Student student = null; try &#123; conn = JDBCUtil.getConnection(); preparedStatement = conn.prepareStatement(sql); resultSet = preparedStatement.executeQuery(); while(resultSet.next())&#123; //获取结果集中int类型的id对应的value int id = resultSet.getInt(&quot;id&quot;); String name = resultSet.getString(&quot;name&quot;); int age = resultSet.getInt(&quot;age&quot;); student = new Student(); student.setAge(age); student.setId(id); student.setName(name); li.add(student); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; JDBCUtil.release(resultSet,preparedStatement,conn); &#125; return li; &#125; 2.Spring模板方式访问数据库—-SpringTemplet 配置xml 12345678&lt;!-- dbcTermplet--&gt; &lt;bean id=&quot;jdbcTemplet&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;studentDao&quot; class=&quot;com.drazen.dao.impl.SpringJdbcDaoImpl&quot;&gt; &lt;property name=&quot;jdbcTemplate&quot; ref=&quot;jdbcTemplet&quot;/&gt; &lt;/bean&gt; 然后再dao层调用jdbcTemplet: 1234567891011121314151617181920212223242526 private JdbcTemplate jdbcTemplate; public JdbcTemplate getJdbcTemplate() &#123; return jdbcTemplate;&#125;public void setJdbcTemplate(JdbcTemplate jdbcTemplate) &#123; this.jdbcTemplate = jdbcTemplate;&#125; public List&lt;Student&gt; selectAllStudents() &#123; final List&lt;Student&gt; li = new ArrayList&lt;Student&gt;(); String sql = &quot;select id ,name,age from tb_student &quot;; jdbcTemplate.query(sql, new RowCallbackHandler() &#123; public void processRow(ResultSet resultSet) throws SQLException &#123; int id = resultSet.getInt(&quot;id&quot;); String name = resultSet.getString(&quot;name&quot;); int age = resultSet.getInt(&quot;age&quot;); Student student = new Student(); student.setAge(age); student.setId(id); student.setName(name); li.add(student); &#125; &#125;); return li; &#125; 其实这些方式代码量很多，且很重复，人力成本比较高 SpringData 方式1.开发环境：maven 依赖 12345678910111213&lt;!-- https://mvnrepository.com/artifact/org.springframework.data/spring-data-jpa --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-jpa&lt;/artifactId&gt; &lt;version&gt;1.10.5.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.hibernate/hibernate-entitymanager --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt; &lt;version&gt;5.1.0.Final&lt;/version&gt; &lt;/dependency&gt; 依赖下载完成后，就要配置bean.xml文件 在bean.xml中配置EntityManagerFactoryEntityManagerFactory是SpringData的核心之一 123456789101112131415161718&lt;bean id=&quot;entityManagerFactory&quot; class=&quot;org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;property name=&quot;jpaVendorAdapter&quot;&gt; &lt;bean class=&quot;org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter&quot;/&gt; &lt;/property&gt; &lt;property name=&quot;packagesToScan&quot; value=&quot;com.drazen&quot;/&gt; &lt;property name=&quot;jpaProperties&quot;&gt; &lt;props&gt; &lt;prop key=&quot;hibernate.ejb.naming_strategy&quot;&gt;org.hibernate.cfg.ImprovedNamingStrategy&lt;/prop&gt; &lt;prop key=&quot;hibernate.dialect&quot;&gt;org.hibernate.dialect.MySQL5InnoDBDialect&lt;/prop&gt;&lt;!--hibernate方言--&gt; &lt;prop key=&quot;hibernate.show_sql&quot;&gt;true&lt;/prop&gt;&lt;!--显示sql--&gt; &lt;prop key=&quot;hibernate.format_sql&quot;&gt;true&lt;/prop&gt;&lt;!--格式化sql--&gt; &lt;prop key=&quot;hibernate.hbm2ddl.auto&quot;&gt;update&lt;/prop&gt;&lt;!--如果没有对应表的话根据实体类生成表--&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; 然后，定义Dao层类型的接口，注意，要实现SpringData功能，首先应该extendsorg.springframework.data.repository.Repository接口或者使用@RepositoryDefinition(domainClass = Employee.class, idClass = Integer.class)注解。其中的domainClass，idClass属性是对应表的实体类与id主键。 Repository类的定义：123public interface Repository&lt;T, ID extends Serializable&gt; &#123;&#125; 1）Repository是一个空接口，标记接口没有包含方法声明的接口,其实有点像Serializable接口 2）如果我们定义的接口EmployeeRepository extends Repository 如果我们自己的接口没有extends Repository，运行时会报错：org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type ‘com.imooc.repository.EmployeeRepository’ available 3) 添加注解能到达到不用extends Repository的功能@RepositoryDefinition(domainClass = Employee.class, idClass = Integer.class) SpringData可以实现通过方法命名规范来自动生成sql进行查询，也就是说，没有方法体 下面是方法名称的命名规范。 要注意：对于按照方法命名规则来使用的话，有弊端： 方法名会比较长： 约定大于配置 对于一些复杂的查询，是很难实现 @Query是一个更好的使用定制sql的工具注解，我通常把它理解为Mybatis中的类似@Select（）酱紫的,而且，它支持命名参数以及索引参数的使用： 就是?这种参数参数插入 支持本地查询123456789101112131415161718192021@Query(&quot;select o from Employee o where id=(select max(id) from Employee t1)&quot;) public Employee getEmployeeByMaxId(); @Query(&quot;select o from Employee o where o.name=?1 and o.age=?2&quot;) public List&lt;Employee&gt; queryParams1(String name, Integer age); @Query(&quot;select o from Employee o where o.name=:name and o.age=:age&quot;) public List&lt;Employee&gt; queryParams2(@Param(&quot;name&quot;) String name, @Param(&quot;age&quot;) Integer age); @Query(&quot;select o from Employee o where o.name like %?1%&quot;) public List&lt;Employee&gt; queryLike1(String name); @Query(&quot;select o from Employee o where o.name like %:name%&quot;) public List&lt;Employee&gt; queryLike2(@Param(&quot;name&quot;) String name); @Query(nativeQuery = true, value = &quot;select count(1) from employee&quot;) public long getCount(); @Modifying @Query(&quot;update Employee o set o.age = :age where o.id = :id&quot;) public void update(@Param(&quot;id&quot;) Integer id, @Param(&quot;age&quot;) Integer age); 关于SPringData中事物 在写操作中需要事物的支持 @Modifying–允许修改 事物在SpringData中的使用 事务在Spring data中的使用： 1）事务一般是在Service层 2）@Query、 @Modifying、@Transactional的综合使用 使用： 在service层中新建service类，并调用update方法： 123456789101112131415161718192021package com.drazen.service;import com.drazen.repository.EmployeeRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import javax.transaction.Transactional;@Servicepublic class EmployeeService &#123; @Autowired private EmployeeRepository employeeRepository;// 手工加入事物注解，并在spring开启自动扫描 @Transactional public void update(Integer id, Integer age) &#123; employeeRepository.update(id, age); &#125;&#125; 关于SpringData JPA1) CrudRepository接口 这个接口其实就是针对实体进行的机械化写操作，简单粗暴快方法有这些： 12345678910111213141516171819202122//保存一个实体&lt;S extends T&gt; S save(S var1);//保存多个实体&lt;S extends T&gt; Iterable&lt;S&gt; save(Iterable&lt;S&gt; var1);//查找一个实体T findOne(ID var1);//查看某个实体记录是否存在boolean exists(ID var1);//查询所有Iterable&lt;T&gt; findAll();//根据id组查询所有结果Iterable&lt;T&gt; findAll(Iterable&lt;ID&gt; var1);//数据字段数量long count();//删除单个void delete(ID var1);//根据实体删除单个void delete(T var1);//删除一组void delete(Iterable&lt;? extends T&gt; var1);//删除所有void deleteAll(); 2)PagingAndSortingRepository 接口支持分页，排序 创建继承了PagingAndSortingRepository的interface12public interface PageRep extends PagingAndSortingRepository&lt;Employee,Integer&gt; &#123;&#125; 1234 // 返回所有实体 Iterable&lt;T&gt; findAll(Sort var1);//返回page对象 Page&lt;T&gt; findAll(Pageable var1); 使用PAGE 构建分页 1234567891011121314151617 @Autowired private PageRep pageRep; public void getPage()&#123; //import org.springframework.data.domain.PageRequest; Pageable pageable = new PageRequest(0,5); Page&lt;Employee&gt; page = pageRep.findAll(pageable);//总页数 System.out.println(page.getTotalPages());// 总记录数 System.out.println(page.getTotalElements());// 当前第几页 System.out.println(page.getNumber());// 当前页面的集合 System.out.println(page.getContent());// 当前页面的记录数 System.out.println(page.getNumberOfElements()); &#125; PageRep 是一个继承了PagingAndSortingRepository的初始interface Pageable 是来自org.springframework.data.domain.PageRequest的类 其实page.getContent()获取到的是List 排序123456789101112131415161718192021 public void getSort()&#123;// import org.springframework.data.domain.Sort.Order;// 进构造器的参数是升序或者降序，类似于order by id desc Sort.Order order = new Sort.Order(Sort.Direction.DESC,&quot;id&quot;);// import org.springframework.data.domain.Sort; Sort sort = new Sort(order);// 将构建好的sort传入PageRequest Pageable pageable = new PageRequest(0,5,sort); Page&lt;Employee&gt; page = pageRep.findAll(pageable); //总页数 System.out.println(page.getTotalPages());// 总记录数 System.out.println(page.getTotalElements());// 当前第几页 System.out.println(page.getNumber());// 当前页面的集合 System.out.println(page.getContent());// 当前页面的记录数 System.out.println(page.getNumberOfElements()); &#125; 3) JpaSpecificationExecutor 接口 其实我觉得这个方法可能还不如直接写sql，但是好像可以对原生sql有很好的支持 Specification封装了JPA Critical 的查询条件 org.springframework.data.jpa.repository目录下 新建接口继承JpaSpecificationExecutor：12public interface JpaSpecificationRepo extends JpaSpecificationExecutor&lt;Employee&gt; &#123;&#125; 组合功能，如分页+排序+查询条件 12345678910111213141516171819202122 public void testNewInterface()&#123;// 假如查询条件设定为age&gt;50 Sort.Order order = new Sort.Order(Sort.Direction.DESC,&quot;id&quot;); Sort sort = new Sort(order);// import org.springframework.data.jpa.domain.Specification; Specification&lt;Employee&gt; specification = new Specification&lt;Employee&gt;() &#123; @Override public Predicate toPredicate(Root&lt;Employee&gt; root, CriteriaQuery&lt;?&gt; criteriaQuery, CriteriaBuilder criteriaBuilder) &#123; Path path = root.get(&quot;age&quot;); /*criteriaBuilder: 构建 * root：实体 * criteriaQuery：查询条件 * * */ return criteriaBuilder.gt(path,50); &#125; &#125;; Pageable pageable = new PageRequest(0,5,sort); Page&lt;Employee&gt; page = pageRep.findAll(specification,pageable); &#125; 总结 SpringData也支持非关系型数据库 总的来说，springdata是一个可以提高开发效率的spring的工具集","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://sunjx93.com/tags/Java/"},{"name":"SpringData","slug":"SpringData","permalink":"http://sunjx93.com/tags/SpringData/"}]},{"title":"Jquery 的一些林林总总","slug":"jquery_log1","date":"2017-05-10T08:52:09.000Z","updated":"2017-05-27T08:16:23.245Z","comments":true,"path":"2017/05/10/jquery_log1/","link":"","permalink":"http://sunjx93.com/2017/05/10/jquery_log1/","excerpt":"Jquery 的一些林林总总 最近看了一本《精妙绝伦JQuery》，里面讲的比较细致，自己都快没耐心啃完了，记下来了一些自己能用到的东西，希望以后可以有所帮助","text":"Jquery 的一些林林总总 最近看了一本《精妙绝伦JQuery》，里面讲的比较细致，自己都快没耐心啃完了，记下来了一些自己能用到的东西，希望以后可以有所帮助 首先 - - 最近面试的时候问到的： 123$(document).ready 与JavaScript里onload方法的区别：$(document).ready(function()&#123;&#125;) 代表的是在DOM加载之前完成代码内加载onload 事件会在页面或图像加载完成后立即发生。 这是jQuery的一些常用方法 1234567891011121314151. .load() 预加载图片2. .ready() 事件监测DOM是否完全加载3. .unload() 在离开页面时或用户单机一个新连接是触发4. .resize() 改变浏览器大小时触发5. .scroll() 用户滚动窗口时触发6. .error() 当http请求遇到错误是触发 可以用来显示备用图片，也就是 网页上的图挂了之后，可以用别的图替代图挂了- - 表达不能23337. .bind() 绑定事件函数8. .live() 提供一个灵活的捕获事件的方式 .live(event type,event handler);9. .delegate() 三个参数：1.选择器 2.事件类型 3.响应函数 捕获鼠标事件123456789click 单击鼠标并释放dbclick 双击触发mousedown 鼠标被按下触发mouseup 鼠标松开后触发mouseenter 鼠标进入某易元素区域时触发mouseleave ..离开时触发mousemove 鼠标在区域内移动时触发mouseout 离开该区域及父元素时触发mouseover 鼠标进入某一元素及父元素时触发 捕获表单事件 123456789change() 表单值改变时触发focus() 敲TAB键触发focusin() 元素或子元素得到焦点时触发focusout() 元素或子元素失去焦点时触发blur() 文本域/文本框失去焦点时触发select() 元素内文本被选中时触发submit() 表单提交时触发reset() 重置 关于网站特效1234567show()hide()toggle() 根据当前状态显示/隐藏 切换状态slideDown() 以向下滑动展开的方式显示元素fadeIn() 元素以淡入的方式显示fadeout() 元素以淡入淡出的方式消失fadeTo() 淡入淡出至某个透明度 关于cookie（这可是他娘的重点）1234567891.如何种cookie function startCookie()&#123; var expirDate = new Date(); expirDate.setDate(expirDate.getDate+30); cookie过期时间 document.cookie = &quot;name=hideCookie;expires=&quot;+expirDate.toUTCString &#125; (可以使用jQuery的cookie插件拿到具体cookie) 注：当没有指明 cookie有效时间时，所创建的cookie有效期默认到用户关闭浏览器为止，所以被称为 “会话cookie（session cookie）”。 1234567$.cookie(&apos;cookName&apos;)$.cookie(&apos;key&apos;,&apos;value&apos;)$.cookie(&apos;key&apos;,&apos;value&apos;,&#123; expires: 7 &#125;);//意思是创建一个7天有效期的cookie$.cookie(&apos;key&apos;,&apos;value&apos;,&#123; expires: 7,path:&apos;/&apos;&#125;);//意思是创建一个7天有效期的cookie,且存储路径为/ 读取cookie：1234567$.cookie(&apos;the_cookie&apos;); // cookie存在 =&gt; &apos;the_value&apos;$.cookie(&apos;not_existing&apos;); // cookie不存在 =&gt; null5.删除cookie，通过传递null作为cookie的值即可：$.cookie(&apos;the_cookie&apos;, null); Ajax 传说中的，标志着人类互联网历史的一大步，就连名字也很后现代化的Ajax Ajax指在不需要刷新页面的情况下，允许客户端应用程序传递数据给服务器并获取数据的一组模式和技术 123456789101.$(selector).load(URL,回调函数&#123; &#125;) $(&apos;#content&apos;).load(&apos;Class5.html&apos;,function(responseText,textStatus,XMLHttpRequest)&#123; //检查不同的响应码 if(XMLHttpRequest.status == 404||XMLHttpRequest.status == 500)&#123; $(&apos;#content&apos;).html(&apos;There has been an error,please try angin later&apos;); &#125; &#125;); 关于响应码 响应码 对应解释 200 成功 301 永久跳转 302 临时跳转 400 错误请求 401 未授权 403 禁止访问 404 未找到 500 服务器错误 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071 2.载入过程的动画 在.load() 之前 $(&apos;#content&apos;).html(&apos;&lt;img...&gt;&apos;); 3.载入部分内容 $(&apos;#content&apos;).load(URL class or id or tag name ) 如： $(&apos;#content&apos;).load(&apos;class1.html.specal&apos;)------意味着该html里只有class=&quot;specal&quot; 的标签才可以被加载 4.get/post 提交表单 Get:服务器在URL中拾取键值对 Post: $.ajax(&#123; type:&apos;post&apos;, url:url, data:data, success:success, dataType:dataType &#125;); post 请求提交数据： 两种方式：标准\\快捷 标准：$.post(url,[data],[success],dataType); 快捷：$.ajax(&#123; url:url, data:data, success:success, dataType:dataType &#125;); 5.操作XML数据 a.XML是跨平台的标准 如何得到xml并解读，展示在html上 $.ajax(&#123; type:&apos;GET&apos;, url:&quot;xx.xml&quot;, dataType:&quot;XML&quot;, success:parseXML ---回调函数 &#125;);生成html function parseXML(xml)&#123; $(xml).find(&quot;Book&quot;).each(function()&#123; var author = $(this).attr(&apos;author&apos;); $(&apos;&lt;li&gt;&lt;/li&gt;&apos;).html(&apos;&lt;b&gt;Author&lt;/b&gt;:&apos;+author).appendTo(&apos;#books&apos;);; &#125;; &#125;6.操作JSon数据 json是JavaScript的表示法，它允许以键值对的形式创建自己的数据结构 a.获取json并生成html $.getJSON();或$.ajax function processJson(data)&#123; $.each(data.books,function(i,item)); &#125; 接下来要做的跟xml类似，你只需要获取item中的键值来生成html","categories":[],"tags":[{"name":"Jquery","slug":"Jquery","permalink":"http://sunjx93.com/tags/Jquery/"}]},{"title":"终于搞定了","slug":"终于搞定了","date":"2017-04-18T08:52:09.000Z","updated":"2019-05-24T08:01:30.140Z","comments":true,"path":"2017/04/18/终于搞定了/","link":"","permalink":"http://sunjx93.com/2017/04/18/终于搞定了/","excerpt":"作为小白中的小白，在升级之路上偶然看到好多大牛自己架设的博客，非常羡慕，在尝试了好久之后，终于初步搞定，微不足道的一大步，记录一下 ：）","text":"作为小白中的小白，在升级之路上偶然看到好多大牛自己架设的博客，非常羡慕，在尝试了好久之后，终于初步搞定，微不足道的一大步，记录一下 ：） 当初是看到这位的博客Giraffe’s Home然后也想自己弄一个。 来记录一下当时我整这破玩意的步骤： 首先首先你需要安装Git 和Node js Git 官网NodeJs 中文网 其次，你需要一个GItHub的账号然后，你就可以来安装hexo了 首先打开的是Git bash：对呀你得用到刚刚安的东西！ npm install -g hexo 初始化然后，执行init命令初始化hexo,命令：（你可以选择这个目录在电脑里的位置） hexo init blog blog就是你的博客根目录，所有的操作都在里面进行。以后提交啥的都要先到这个目录再提交。 hexo generate（hexo g）生成页面 如果你生成页面的时候报错，大概是hexo版本的问题，你需要先执行： npm install hexo-deployer-git –save 启动本地服务 hexo server 然后在 http://localhost4000这里就可以看到本地的博客了。 如果你想发布到网站上你需要登录GitHub账号，然后新建一个仓库（Repository），命名规则是你的GitHub用户名.github.io比如我的：Drazen08.github.io 然后：打开你本地blog文件夹，里面有一个_config.yml文件，这个需要做一些小改动： 需要注意的是！所有 ：冒号后面都要跟一个空格，要不然会报错，这里曾经困扰我好久！！！！123456title: Drazen -- 标题subtitle: the stack of it nerds -- 大概是类似座右铭之类的东西description: start from zeroauthor: JFuncnoviclanguage: zh-Hanstimezone: AsiaShanghai 需要注意的是language 和timezone ，语言和时区。 这里： 1theme: huno huno是我下载的主题，放在{目录}/theme/huno下。 最重要的是1234deploy type: git repo: git@github.comDrazen08Drazen08.github.io.git branch: master repo的地址是ssl形式的，其实好像不用这么麻烦，或许是我被墙了。。 最后执行hexo deploy 在浏览器中输入 你自己的.github.io 就可以访问了 部署步骤每次部署的步骤，可按以下三步来进行。 hexo clean hexo generate hexo deploy 一些常用命令：hexo newpostName #新建文章 hexo new pagepageName #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，ctrl + c关闭server） hexo deploy #将.deploy目录部署到GitHub hexo help # 查看帮助 hexo version #查看Hexo的版本 对了，当时好像我配置了一个ssh码关联到github上，忘记了。","categories":[],"tags":[{"name":"Hexo_Github","slug":"Hexo-Github","permalink":"http://sunjx93.com/tags/Hexo-Github/"}]}]}